<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">Dynabots</title>
<generator uri="https://github.com/mojombo/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="/feed.xml" />
<link rel="alternate" type="text/html" href="" />
<updated>2014-11-13T14:45:17-08:00</updated>
<id>/</id>
<author>
  <name></name>
  <uri>/</uri>
  <email></email>
</author>


<entry>
  <title type="html"><![CDATA[Evaluation Week (Pay No Attention to that Man Behind the Curtain)]]></title>
  <link>/evaluation-week</link>
  <id>/evaluation-week</id>
  <published>2014-08-04T00:00:00-07:00</published>
  <updated>2014-08-04T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;p&gt;This past week has been a whirlwind of focusing our prototyping efforts, having target audience users test this prototype, and further refining the prototype.
### Our New Focus: Exploration&lt;/p&gt;

&lt;p&gt;We made a huge breakthrough after our prototyping presentation of a couple weeks ago, which allowed us to narrow our focus. Because of the medium-high fidelity and resources for the prototype we had created for the “capture”, or 3D construction of environments through crowd-sourced 3D image contributions, we decided that the capture interface was now at a high-enough fidelity for our purposes. As a team, we became more interested in the “explore” part of our design over time, and so chose to focus our further prototyping and evaluation on that experience.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 61.01847679134745%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/Initial_Prototypes-750x458-3fd390.png&quot; srcset=&quot;/images/generated/evaluation-week/Initial_Prototypes-750x458-3fd390.png 562w, /images/generated/evaluation-week/Initial_Prototypes-750x458-3fd390.png 562w 2x, /images/generated/evaluation-week/Initial_Prototypes-1500x914-3fd390.png 2x, /images/generated/evaluation-week/Initial_Prototypes-750x458-3fd390.png&quot; width=&quot;750&quot; height=&quot;457&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;prototype-changes&quot;&gt;Prototype Changes&lt;/h3&gt;

&lt;p&gt;After a brainstorming session, we came up with a design spec of features that we wanted the prototype to have, our reasons for having that feature, how that feature would look in the prototype, and how we would evaluate that feature.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 36.39004149377593%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/Explore_Mode_Design_Spec-750x273-e74796.png&quot; srcset=&quot;/images/generated/evaluation-week/Explore_Mode_Design_Spec-750x273-e74796.png 562w, /images/generated/evaluation-week/Explore_Mode_Design_Spec-750x273-e74796.png 562w 2x, /images/generated/evaluation-week/Explore_Mode_Design_Spec-1500x544-e74796.png 2x, /images/generated/evaluation-week/Explore_Mode_Design_Spec-750x273-e74796.png&quot; width=&quot;750&quot; height=&quot;272&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 133.33333333333331%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/IMG_3133-750x1000-7a9678.jpg&quot; srcset=&quot;/images/generated/evaluation-week/IMG_3133-750x1000-7a9678.jpg 562w, /images/generated/evaluation-week/IMG_3133-750x1000-7a9678.jpg 562w 2x, /images/generated/evaluation-week/IMG_3133-1500x2000-7a9678.jpg 2x, /images/generated/evaluation-week/IMG_3133-750x1000-7a9678.jpg&quot; width=&quot;750&quot; height=&quot;1000&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;Feedback we received on certain aspects of our prototype caused us to redesign, scrap, or add to the prototype. Specifically, we abandoned the “click wheel” we had designed for navigating the 3D environment, redesigned the types of interactions and filters available with the various forms of media (audio, images, video, and comments) in our design, and developed a concept for viewing an overview of the environment, as well as bookmarking markers in the environment. In thinking about how to create the experience of these changes, we went back to our design principles of a sense of immersion, intuitive navigation, and the ability to easily search for content.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 56.11285266457679%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/clickwheel%20screenshot-638x358-187270.png&quot; srcset=&quot;/images/generated/evaluation-week/clickwheel%20screenshot-638x358-187270.png 478w, /images/generated/evaluation-week/clickwheel%20screenshot-638x358-187270.png 478w 2x, /images/generated/evaluation-week/clickwheel%20screenshot-638x358-187270.png 2x, /images/generated/evaluation-week/clickwheel%20screenshot-638x358-187270.png&quot; width=&quot;638&quot; height=&quot;358&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.52123230641132%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/Stitch%20aerial%20view%20screenshot-750x559-ad11ac.png&quot; srcset=&quot;/images/generated/evaluation-week/Stitch%20aerial%20view%20screenshot-750x559-ad11ac.png 562w, /images/generated/evaluation-week/Stitch%20aerial%20view%20screenshot-750x559-ad11ac.png 562w 2x, /images/generated/evaluation-week/Stitch%20aerial%20view%20screenshot-1201x894-ad11ac.png 2x, /images/generated/evaluation-week/Stitch%20aerial%20view%20screenshot-750x559-ad11ac.png&quot; width=&quot;750&quot; height=&quot;558&quot; /&gt;&lt;/figure&gt;

&lt;h4 id=&quot;navigation&quot;&gt;Navigation&lt;/h4&gt;

&lt;p&gt;In place of the click wheel, we chose to have users navigate the space using gestures we had chosen, based upon our assumptions of intuitive navigation. These gestures were swiping left or right to pan left or right in the space, swiping up or down to tilt the view and look upward or downward, and pinching outwards to walk forward in the space.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: %;&quot;&gt;&lt;img src=&quot;false&quot; srcset=&quot;false 562w, false 562w 2x, false 2x, false&quot; width=&quot;750&quot; height=&quot;AUTO&quot; /&gt;&lt;/figure&gt;

&lt;h4 id=&quot;new-concepts&quot;&gt;New Concepts&lt;/h4&gt;

&lt;p&gt;For interactions with the markers, we decided to call out the curated, editor’s pick markers and markers contributed by readers through differences in color. We also developed an interface for filtering these markers based on media type and contribution type—editors, readers, and your own markers.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 133.33333333333331%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/IMG_3143-750x1000-ef764a.jpg&quot; srcset=&quot;/images/generated/evaluation-week/IMG_3143-750x1000-ef764a.jpg 562w, /images/generated/evaluation-week/IMG_3143-750x1000-ef764a.jpg 562w 2x, /images/generated/evaluation-week/IMG_3143-1500x2000-ef764a.jpg 2x, /images/generated/evaluation-week/IMG_3143-750x1000-ef764a.jpg&quot; width=&quot;750&quot; height=&quot;1000&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.81234361968308%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/markers%20popover%20with%20filters-750x561-7f6f6b.png&quot; srcset=&quot;/images/generated/evaluation-week/markers%20popover%20with%20filters-750x561-7f6f6b.png 562w, /images/generated/evaluation-week/markers%20popover%20with%20filters-750x561-7f6f6b.png 562w 2x, /images/generated/evaluation-week/markers%20popover%20with%20filters-1199x897-7f6f6b.png 2x, /images/generated/evaluation-week/markers%20popover%20with%20filters-750x561-7f6f6b.png&quot; width=&quot;750&quot; height=&quot;561&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;We also came up with a new concept for the explore interface that really excited us. 
We had always thought about including the ability to bookmark markers in the environment, but we started thinking more about what you could do with these bookmarks. In the end, we felt it could be a type of curation similar to the initial view of the space, which shows only the markers created by the journalist. Your bookmarked markers could serve as your own guided tour of the environment, that you could use for your own reference or share with others.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.16722408026756%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/aerial%20view%20with%20bookmarks-750x564-f6d74e.png&quot; srcset=&quot;/images/generated/evaluation-week/aerial%20view%20with%20bookmarks-750x564-f6d74e.png 562w, /images/generated/evaluation-week/aerial%20view%20with%20bookmarks-750x564-f6d74e.png 562w 2x, /images/generated/evaluation-week/aerial%20view%20with%20bookmarks-1196x898-f6d74e.png 2x, /images/generated/evaluation-week/aerial%20view%20with%20bookmarks-750x564-f6d74e.png&quot; width=&quot;750&quot; height=&quot;563&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;We also thought it would be interesting for publishers and readers alike to see what spaces of an environment had been most contributed to, in the form of a heat map of markers over an aerial view of the environment. This became the first view of the space the user would see after finding the environment, and also led us to develop an interaction that allowed the user to slowly “fly down” from the aerial view and see a little more of the space before starting their walkthrough.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.79061976549414%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/heatmap%20screenshot-750x561-085830.png&quot; srcset=&quot;/images/generated/evaluation-week/heatmap%20screenshot-750x561-085830.png 562w, /images/generated/evaluation-week/heatmap%20screenshot-750x561-085830.png 562w 2x, /images/generated/evaluation-week/heatmap%20screenshot-1194x892-085830.png 2x, /images/generated/evaluation-week/heatmap%20screenshot-750x561-085830.png&quot; width=&quot;750&quot; height=&quot;560&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;deciding-what-to-test&quot;&gt;Deciding What to Test&lt;/h3&gt;

&lt;p&gt;We had another brainstorming on all of the features that we were unsure about in our prototype, as well as overarching questions about the experience, based on our design principles.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/IMG_3146-750x563-e415f3.jpg&quot; srcset=&quot;/images/generated/evaluation-week/IMG_3146-750x563-e415f3.jpg 562w, /images/generated/evaluation-week/IMG_3146-750x563-e415f3.jpg 562w 2x, /images/generated/evaluation-week/IMG_3146-1500x1124-e415f3.jpg 2x, /images/generated/evaluation-week/IMG_3146-750x563-e415f3.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;We then voted on the questions we were most interested in, and came up with five that we would evaluate with participants. These included ways of navigating, how people made sense of a 3D space, how people would contribute to the space, and what people thought of our visual interface and icon design.&lt;/p&gt;

&lt;h3 id=&quot;recruiting-participants&quot;&gt;Recruiting Participants&lt;/h3&gt;

&lt;p&gt;We chose to reach out to the DUB mailing list at the University of Washington, as well as a UW group on Facebook, because we felt that our target audience would include a wide range of people. We also created a screener survey to discover user’s news reading habits, familiarity with tablets, familiarity with 3D environments, and demographics information. As we sent out our requests for participants, we gave a little background on our project focus and what we were trying to accomplish.&lt;/p&gt;

&lt;p&gt;Thankfully, we received a lot of interest in our project, and so had a lot of potential participants to choose from. In the end, we tested our prototype with 2 males and 2 females, age range 18-39, from a variety of majors: English, biochemistry, geology, and prospective informatics. All participants read the news fairly often, had at least some experience with a tablet, and a small amount of experience with 3D environments.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 90.39145907473309%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/catalyst%20survey%20screenshot-750x678-22aa79.png&quot; srcset=&quot;/images/generated/evaluation-week/catalyst%20survey%20screenshot-750x678-22aa79.png 562w, /images/generated/evaluation-week/catalyst%20survey%20screenshot-750x678-22aa79.png 562w 2x, /images/generated/evaluation-week/catalyst%20survey%20screenshot-843x761-22aa79.png 2x, /images/generated/evaluation-week/catalyst%20survey%20screenshot-750x678-22aa79.png&quot; width=&quot;750&quot; height=&quot;677&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;testing-approach&quot;&gt;Testing Approach&lt;/h3&gt;
&lt;p&gt;#### Behavioral Prototype
Because this is a newer interaction model in terms of 3D environments and touch gestures, we wanted to know how people would like to move around this environment and what they considered important within the environment. Therefore, we chose to have participants evaluate a behavioral prototype.
The prototype consisted of an interactive prototype comprised of stills, video, and motion graphics, linked together using Keynote. This interactive prototype simulated a 3D environment participants could explore, which in this case was Red Square at the University of Washington, as we could easily take photos and videos to include in the prototype. Because this was a behavioral prototype, we had a set of pre-determined tasks the user needed to accomplish, as well as certain areas of Red Square they would see, based on the video we had captured.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 60.86956521739131%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/annotation%20view%20screenshot-621x378-5571bb.png&quot; srcset=&quot;/images/generated/evaluation-week/annotation%20view%20screenshot-621x378-5571bb.png 465w, /images/generated/evaluation-week/annotation%20view%20screenshot-621x378-5571bb.png 465w 2x, /images/generated/evaluation-week/annotation%20view%20screenshot-621x378-5571bb.png 2x, /images/generated/evaluation-week/annotation%20view%20screenshot-621x378-5571bb.png&quot; width=&quot;621&quot; height=&quot;378&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 49.217809867629356%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/audio%20view%20screenshot-750x369-5eb9fd.png&quot; srcset=&quot;/images/generated/evaluation-week/audio%20view%20screenshot-750x369-5eb9fd.png 562w, /images/generated/evaluation-week/audio%20view%20screenshot-750x369-5eb9fd.png 562w 2x, /images/generated/evaluation-week/audio%20view%20screenshot-831x409-5eb9fd.png 2x, /images/generated/evaluation-week/audio%20view%20screenshot-750x369-5eb9fd.png&quot; width=&quot;750&quot; height=&quot;369&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 67.74647887323944%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/image%20view%20screenshot-710x481-6f2f19.png&quot; srcset=&quot;/images/generated/evaluation-week/image%20view%20screenshot-710x481-6f2f19.png 532w, /images/generated/evaluation-week/image%20view%20screenshot-710x481-6f2f19.png 532w 2x, /images/generated/evaluation-week/image%20view%20screenshot-710x481-6f2f19.png 2x, /images/generated/evaluation-week/image%20view%20screenshot-710x481-6f2f19.png&quot; width=&quot;710&quot; height=&quot;481&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 89.08145580589255%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/annotation%20tutorial%20screenshot-577x514-5c0f39.png&quot; srcset=&quot;/images/generated/evaluation-week/annotation%20tutorial%20screenshot-577x514-5c0f39.png 432w, /images/generated/evaluation-week/annotation%20tutorial%20screenshot-577x514-5c0f39.png 432w 2x, /images/generated/evaluation-week/annotation%20tutorial%20screenshot-577x514-5c0f39.png 2x, /images/generated/evaluation-week/annotation%20tutorial%20screenshot-577x514-5c0f39.png&quot; width=&quot;577&quot; height=&quot;514&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 116.46090534979423%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/add%20annotation%20screenshot-243x283-3c95e2.png&quot; srcset=&quot;/images/generated/evaluation-week/add%20annotation%20screenshot-243x283-3c95e2.png 182w, /images/generated/evaluation-week/add%20annotation%20screenshot-243x283-3c95e2.png 182w 2x, /images/generated/evaluation-week/add%20annotation%20screenshot-243x283-3c95e2.png 2x, /images/generated/evaluation-week/add%20annotation%20screenshot-243x283-3c95e2.png&quot; width=&quot;243&quot; height=&quot;283&quot; /&gt;&lt;/figure&gt;

&lt;h4 id=&quot;card-sort&quot;&gt;Card Sort&lt;/h4&gt;

&lt;p&gt;We had specific questions about how the markers were shown in the environment, in terms of media type and contribution type. Our interface had a series of filters the user could use to pick what types of markers they wanted to see, but we also wanted to know what types of markers and contributions seemed to generally be most important to the users. In this way, we could determine what types of markers to show in the default view. In order to test this, we performed a card sort exercise with four people. There were 12 cards total, the four media types and contributor type of journalist, other readers, self. The participants were asked to put the cards in order of what they deemed most important, and we then asked some follow-up questions about their choices.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/IMG_8161-750x500-41680f.JPG&quot; srcset=&quot;/images/generated/evaluation-week/IMG_8161-750x500-41680f.JPG 562w, /images/generated/evaluation-week/IMG_8161-750x500-41680f.JPG 562w 2x, /images/generated/evaluation-week/IMG_8161-1500x1000-41680f.JPG 2x, /images/generated/evaluation-week/IMG_8161-750x500-41680f.JPG&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/IMG_8189-750x500-6d75a9.JPG&quot; srcset=&quot;/images/generated/evaluation-week/IMG_8189-750x500-6d75a9.JPG 562w, /images/generated/evaluation-week/IMG_8189-750x500-6d75a9.JPG 562w 2x, /images/generated/evaluation-week/IMG_8189-1500x1000-6d75a9.JPG 2x, /images/generated/evaluation-week/IMG_8189-750x500-6d75a9.JPG&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;h4 id=&quot;testing-script&quot;&gt;Testing Script&lt;/h4&gt;
&lt;p&gt;In terms of the general questions we had about our prototype, we thought about navigating the 3D space and evaluating how the user would try to navigate the space versus the gestures we had chosen. We also wanted to measure the clarity of our icon meanings for various media types, as well as how to navigate back to the article that the 3D environment is related to. We also had questions about the clarity and types of filters for exploring the markers in the environment, and the ease in which the user could contribute their own marker to the space. Because there were a limited number of tasks that could be accomplished through this prototype, and a high chance of something happening that we did not intend in terms of the user trying something out of order, we first showed the user a scene in the prototype and asked them to tell us what they expected to happen in the scene, what they expected to be able to do based on what they saw in the environment. Then, we asked them to perform specific gestures or tasks, ensuring for the most part that the prototype would not break.
These tasks included showing us how they would find an article about red square, enter the environment from aerial view. move left, right, up, down, and forward, to find a specific audio file, identifying the other types of media, identify contributor types, express a preference for contributor, filter them, add their own marker to the scene, and return to the article view.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.google.com/document/d/16vst5lHMAqdzdZSVQFpsQrHDzmxTH2lnVh2OjU4vqwg/edit?usp=sharing&quot;&gt;View the testing script here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;testing-environment&quot;&gt;Testing Environment&lt;/h3&gt;

&lt;p&gt;We chose to do our testing in the Allen Research Commons in a private room when possible, as well as in the MHCI+D studio.  We had one facilitator sit next to the participant, who tested our prototype on an iPad. One team member operated a video camera on a tripod across the room from the participant to record body language and facial expressions, and a small camera on the tabletop recorded the iPad screen and hand gestures of the participant. A small microphone was also placed next to the participants. Another team member sat off to the side, controlling the prototype transitions through Keynote. The remaining two participants acted as notetakers, one recording dialogue and actions, and the other recording facial expressions and body language. This would help to discover the participant’s possible real reactions to what they were asked, rather than relying solely on what they told us.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/IMG_8204-750x500-ca7389.JPG&quot; srcset=&quot;/images/generated/evaluation-week/IMG_8204-750x500-ca7389.JPG 562w, /images/generated/evaluation-week/IMG_8204-750x500-ca7389.JPG 562w 2x, /images/generated/evaluation-week/IMG_8204-1500x1000-ca7389.JPG 2x, /images/generated/evaluation-week/IMG_8204-750x500-ca7389.JPG&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;our-findings&quot;&gt;Our Findings&lt;/h3&gt;

&lt;p&gt;There were both positives and negatives to our findings. For instance, our media icons were understandable, but our toolbar icons were only understandable to about half the participants at first sight. Once participants tapped the icons, however, the purpose of the icons became clear. 
We also gained some very interesting insights into how our participants wanted to navigate and how they viewed marker placement. The act of “walking forward” was split between participants first wanting to swipe downward, and participants who first wanted to pinch out as we had intended. However, all participants seemed to have more of a notion of “zooming in” rather than walking through a space. They all expressed a wish to double tap a location to instantly move there, rather than having to move forward over time. This was most apparent as the participants saw the aerial view of the environment, and is an idea that we might like to implement in future.&lt;/p&gt;

&lt;p&gt;The placement of the markers was also very important. For instance, one of the comment icons was arbitrarily placed in a part of the environment that had two people standing together, and at least half of the participants thought the comment icon had something to do with a conversation between the two people. Because the markers also have a pointed bottom, most participants expected, understandably, that the marker would relate directly to what was underneath it, even when we had chosen a location arbitrarily. Participants also thought the visual layout was overwhelming or cluttered when both journalist and reader contributions were shown, and one of the participants expressed a wish that the markers were grouped very specifically by landmark, and possibly aggregated. For the second group of participants, we now explored the possibility of having only four markers for each landmark, with each marker expanding to include a list of all contributions of that media type for easier browsing. During the test, we showed them both the original markers and filters view, and our updated version second. The aggregate view was preferable to that group of users, because it reduced visual clutter.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.82233502538071%;&quot;&gt;&lt;img src=&quot;/images/generated/evaluation-week/new%20filters%20screenshot-750x561-893719.png&quot; srcset=&quot;/images/generated/evaluation-week/new%20filters%20screenshot-750x561-893719.png 562w, /images/generated/evaluation-week/new%20filters%20screenshot-750x561-893719.png 562w 2x, /images/generated/evaluation-week/new%20filters%20screenshot-985x737-893719.png 2x, /images/generated/evaluation-week/new%20filters%20screenshot-750x561-893719.png&quot; width=&quot;750&quot; height=&quot;561&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;We also discovered that participants were optimistic about the ability to save the markers. One participant said she would use it to plan a route through an unfamiliar area, while another wanted to use it as a record of where he had already visited in the environment, or areas of the environment he would like to explore later.&lt;/p&gt;

&lt;h3 id=&quot;next-steps&quot;&gt;Next Steps&lt;/h3&gt;

&lt;p&gt;For future iterations of this prototype, we plan to make a version using the Unity 3D game engine. We believe this prototype would deliver an experience closer to the envisioned final product, as it would solve the lag and limited navigation shortcomings of our current behavioral prototype. We are also looking into how to aggregate contributions by media type, and how to best display these “aggregate markers”. Finally, we are looking into adding a “tap to move forward” navigation model that lets people tap a location to move there in addition to the touch gestures we already modeled.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/evaluation-week&quot;&gt;Evaluation Week (Pay No Attention to that Man Behind the Curtain)&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on August 04, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Prototyping Up a Storm - Realizing The Stitch Interface]]></title>
  <link>/blog/prototyping-up-a-storm-realizing-the-stitch-interface</link>
  <id>/blog/prototyping-up-a-storm-realizing-the-stitch-interface</id>
  <published>2014-07-23T00:00:00-07:00</published>
  <updated>2014-07-23T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;p&gt;Diving into interface design and prototyping has been a long time coming. After &lt;a href=&quot;http://www.dynabots.com/blog/stich-a-new-concept-with-a-new-direction/&quot;&gt;separating our system into discrete components&lt;/a&gt;, we started planning, sketching, and writing design guidelines for each part of Stitch. Stitch’s most unique features are crowdsourced capture of newsworthy locations and immersive exploration of these spaces, so our prototype work focused closely on these two components.&lt;/p&gt;

&lt;h3 id=&quot;the-capture-experience&quot;&gt;The Capture Experience&lt;/h3&gt;

&lt;p&gt;Early on, we started thinking about the capture experience for Stitch, since a poor experience with this interface could prevent people from even participating in the collaborative work required to build these immersive, annotated exploration spaces we had in mind. Our first question about capture was simply, “how will we actually direct people to capture the environment?” There were many more questions about capture embedded into this one, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;How do current 2D and 3D capture interfaces work? What makes a “good” capture experience?&lt;/li&gt;
  &lt;li&gt;What is the conceptual model behind the capture experience? How will we reflect this in our interface to create an accurate mental model?&lt;/li&gt;
  &lt;li&gt;How can we direct or encourage people to capture certain portions of a scene that haven’t been captured yet?&lt;/li&gt;
  &lt;li&gt;How do we balance directed capture with “free capture” to make sure the system has both individual and communal value for people?&lt;/li&gt;
  &lt;li&gt;What visual appearance should hints and other interface elements have?&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2679-750x563-e953ec.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2679-750x563-e953ec.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2679-750x563-e953ec.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2679-1500x1124-e953ec.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2679-750x563-e953ec.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2680-750x563-227ace.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2680-750x563-227ace.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2680-750x563-227ace.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2680-1500x1124-227ace.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2680-750x563-227ace.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;We looked at several existing interfaces, including panorama stitching tools like the iOS Camera app, &lt;a href=&quot;https://www.google.com/maps/about/contribute/photosphere/&quot;&gt;Google Photo Sphere&lt;/a&gt;, &lt;a href=&quot;https://itunes.apple.com/us/app/photosynth/id430065256?mt=8&quot;&gt;the Photosynth panorama app for iOS&lt;/a&gt;, and more. After further discussing the paradigm to use for our capture interface based on existing approaches for depth capture (&lt;a href=&quot;http://research.microsoft.com/en-us/projects/surfacerecon/&quot;&gt;KinectFusion&lt;/a&gt;, &lt;a href=&quot;https://www.youtube.com/watch?v=Qe10ExwzCqk&quot;&gt;Project Tango&lt;/a&gt;), we decided to go with a “multiple single-shot” approach, as it felt like a familiar balance between depth capture and taking a standard photo.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2844-750x563-126fe4.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2844-750x563-126fe4.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2844-750x563-126fe4.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2844-1500x1124-126fe4.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2844-750x563-126fe4.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;pinning-down-our-prototype-ambitions&quot;&gt;Pinning Down Our Prototype Ambitions&lt;/h3&gt;

&lt;p&gt;We eagerly started whiteboarding our interface designs and questions, but before long, we needed to very specifically define which prototypes we were actually building, at what level of fidelity, answering which questions. We had even started creating some prototypes, but their direction and purpose were lacking and unclear as a whole group. Hence, we created two frameworks: a Prototype Inventory and a Capture UI Variables summary.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2851-750x563-0c6080.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2851-750x563-0c6080.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2851-750x563-0c6080.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2851-1500x1124-0c6080.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2851-750x563-0c6080.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;The Prototype Inventory listed each of our currently planned prototypes and the motivation behind creating them.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2849-750x563-626ba2.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2849-750x563-626ba2.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2849-750x563-626ba2.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2849-1500x1124-626ba2.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2849-750x563-626ba2.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;The Capture UI Variables framework came out of a discussion that revealed differing opinions on why and how to prototype the capture UI. We used this framework to pin down consistent elements and specifically target specific questions by varying certain parts.&lt;/p&gt;

&lt;h3 id=&quot;explaining-stitch-efficiently-with-a-video-prototype&quot;&gt;Explaining Stitch Efficiently with a Video Prototype&lt;/h3&gt;

&lt;p&gt;We took some time to create a unique one-off prototype: a compact video prototype of Stitch, which defines and explains the system through words and graphics. We created this explanation to help people better grasp the core concepts of the system. Our previous storyboard videos were successful in this regard, so this shorter video aimed to tighten up and compact the storytelling from those, providing a quick, solid, and accessible introduction to Stitch.&lt;/p&gt;

&lt;div class=&quot;video-container vimeo&quot;&gt;&lt;iframe width=&quot;960&quot; height=&quot;540&quot; src=&quot;//player.vimeo.com/video/101036788?portrait=0&amp;amp;title=0&amp;amp;byline=0&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h3 id=&quot;prototyping-for-mobile-first&quot;&gt;Prototyping for Mobile First&lt;/h3&gt;

&lt;p&gt;For the rest of our specific interfaces, we made the important decision to start prototyping mobile phone interfaces &lt;em&gt;first&lt;/em&gt;. Our belief was that these mobile interfaces should contain the minimum functionality required to realize our desired experience, and from there we could expand those interfaces to accommodate larger screens.&lt;/p&gt;

&lt;h3 id=&quot;the-explore-interface-focus-on-navigation-controls&quot;&gt;The Explore Interface: Focus on Navigation Controls&lt;/h3&gt;

&lt;p&gt;The second tent pole of the Stitch is immersive exploration of a location and content embedded within the space in virtual reality. We thus started conceptualizing and prototyping this component as well, once we had made progress with our capture prototypes.&lt;/p&gt;

&lt;p&gt;We considered navigation controls to be the most challenging part of the explore interface. There were a few reasons for this: one, we had many different movement control paradigms to choose from, many of which come from first-person video gaming on multiple platforms. We wanted this interface to be &lt;strong&gt;approachable for people who weren’t necessarily gamers&lt;/strong&gt;, and we also want to navigation controls that best supported exploration of a real-world space. Early on we looked at the movement controls used in &lt;a href=&quot;https://itunes.apple.com/us/app/epic-citadel/id388888815?mt=8&quot;&gt;Epic Games’ Epic Citadel&lt;/a&gt; for iPad, an Unreal Engine demo with a first-person camera view and “dual analog” movement controls, implemented as on-screen thumb sticks.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2840-750x563-3e1244.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2840-750x563-3e1244.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2840-750x563-3e1244.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2840-1500x1124-3e1244.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2840-750x563-3e1244.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;We chose to prototype navigation controls which optimized certain types of movements. Two of the controls appear on-screen, while one is purely gestural, meant for capitative touch screens.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 133.33333333333331%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2948-750x1000-3493fa.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2948-750x1000-3493fa.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2948-750x1000-3493fa.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2948-1500x2000-3493fa.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2948-750x1000-3493fa.jpg&quot; width=&quot;750&quot; height=&quot;1000&quot; /&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Flick and swipe anywhere on-screen to pan and tilt.&lt;/strong&gt; This control supports stationary surveying of a scene, as when looking at a building facade, for example.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;A quick pan ring for rapid panning.&lt;/strong&gt; This control supports quickly turning around in-place when tapping and dragging along the outside of a circular control on-screen.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;A stick for forward movement and panning while walking.&lt;/strong&gt; Inspired by the video game &lt;a href=&quot;http://en.wikipedia.org/wiki/Metroid_Prime&quot;&gt;Metroid Prime&lt;/a&gt;, this “analog stick” supports tapping and dragging upwards to walk forward, just like the left stick in a standard “dual analog” configuration. Unlike the latter, however, horizontal movement while using our control maps to panning instead of strafing (walking sideways). This change allows the control to support forward movement with banking, as when walking down a curved corridor.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;realizing-a-more-cohesive-experience-with-the-stitch-mobile-app&quot;&gt;Realizing a More Cohesive Experience with the Stitch Mobile App&lt;/h3&gt;

&lt;p&gt;As we started building up these two different interfaces, capture and explore, we realized the need to fit them into a single, cohesive information architecture. Given our familiarity with Apple mobile devices, we chose to fit the interfaces into a mobile app paradigm. We envisioned an app which brought together several pieces of content:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A publisher’s regular news articles&lt;/li&gt;
  &lt;li&gt;News articles attached with completed immersive spaces&lt;/li&gt;
  &lt;li&gt;Motivating “capture challenges” soliciting people’s help in capturing and completing work-in-progress scenes&lt;/li&gt;
  &lt;li&gt;A “Free Capture” mode to support the creation of personal depth captures&lt;/li&gt;
  &lt;li&gt;A list of previous personal captures&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 100.0%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/app%20IA-750x750-77ae7b.png&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/app%20IA-750x750-77ae7b.png 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/app%20IA-750x750-77ae7b.png 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/app%20IA-1000x1000-77ae7b.png 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/app%20IA-750x750-77ae7b.png&quot; width=&quot;750&quot; height=&quot;750&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_3006-750x563-b2292f.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_3006-750x563-b2292f.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_3006-750x563-b2292f.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_3006-1500x1124-b2292f.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_3006-750x563-b2292f.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;dividing-and-conquering-again-and-again&quot;&gt;Dividing and Conquering (Again and Again)&lt;/h3&gt;

&lt;p&gt;We chose to conceptualize a whole system: not a series of discrete components, but a full system, with Stitch. This choice made it difficult to scope down our prototyping ambitions. At one point, we were going to make two interactive capture interface prototypes and several explore interface prototypes using static and motion graphics. We also had begun to consider a tablet interface in addition to the smaller mobile phone interface.&lt;/p&gt;

&lt;p&gt;Dividing our efforts like this shouldn’t have meant uncoordinating them, however, so we reached a point where we had to refocus: &lt;strong&gt;what prototypes were we building, and what did those prototypes help us evaluate?&lt;/strong&gt; We realized we couldn’t just test the individual interface components out of context, so we started to approach our prototyping goals through a more coherent vision. At one point we discussed integrating all our prototype components into a single app to test with. Ultimately this was the right approach for many reasons, but time didn’t permit it—so what did we do?&lt;/p&gt;

&lt;p&gt;We reorganized our prototypes by interface and by medium, which is shown in the whiteboard photo below.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 133.33333333333331%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2917-750x1000-3faa85.jpg&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2917-750x1000-3faa85.jpg 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2917-750x1000-3faa85.jpg 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2917-1500x2000-3faa85.jpg 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/IMG_2917-750x1000-3faa85.jpg&quot; width=&quot;750&quot; height=&quot;1000&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;The plan was to have three levels of fidelity—images, videos, and real-time interactive graphics—and to “glue” these pieces together with two “wireframe” apps, one for mobile phones and another for tablets. This unified approach meant scrapping our second interactive capture prototype and buckling down on app interface design to make a coherent experience. This approach also included the use of motion graphics to prototype the look and feel of immersive walkthroughs on tablets, which had been planned for a while, but had gotten lost in the flurry of interest around capture UI prototyping.&lt;/p&gt;

&lt;h3 id=&quot;prototype-deliverables&quot;&gt;Prototype Deliverables&lt;/h3&gt;

&lt;p&gt;We gave ourselves a tremendous amount of work and a high bar for completeness, so how’d we end up doing? On Monday we presented three prototypes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A comprehensive &lt;a href=&quot;https://popapp.in/w/projects/53cc98c0f9cecd44159d4a18/preview/53cc9903eeeefe26596581b0&quot;&gt;Stitch mobile app interface prototype&lt;/a&gt;, including static mockups of the capture and challenge UIs, as well as some visual variations to more prominently emphasize challenge and capture.&lt;/li&gt;
  &lt;li&gt;A separate interactive Capture / Challenge UI prototype.&lt;/li&gt;
  &lt;li&gt;A tablet interface prototype with static, motion, and basic interactive mockups of what scene annotations and navigation might look like.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 56.25%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.001-750x422-c31815.png&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.001-750x422-c31815.png 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.001-750x422-c31815.png 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.001-1500x842-c31815.png 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.001-750x422-c31815.png&quot; width=&quot;750&quot; height=&quot;421&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;We ended up getting pretty close to our production goals for prototyping, though some parts didn’t quite come together as smoothly as we would’ve hoped. Everyone on the team ended up directly contributing prototype materials, so instead of having a bottleneck of a single visual designer on the team, our bottleneck was instead the work needed to coordinate and bring together everybody’s pieces.&lt;/p&gt;

&lt;h3 id=&quot;our-prototype-evaluation-strategy&quot;&gt;Our Prototype Evaluation Strategy&lt;/h3&gt;

&lt;p&gt;In the end, our prototypes exist to help us answer questions, so the next step is to evaluate the prototypes according to a series of concrete evaluation questions. We have much more work ahead of us to perform formal evaluations with these prototypes, but the sets of questions below set our trajectory.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 56.25%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.007-750x422-16e168.png&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.007-750x422-16e168.png 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.007-750x422-16e168.png 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.007-1500x842-16e168.png 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.007-750x422-16e168.png&quot; width=&quot;750&quot; height=&quot;421&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 56.25%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.008-750x422-e6b0a3.png&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.008-750x422-e6b0a3.png 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.008-750x422-e6b0a3.png 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.008-1500x842-e6b0a3.png 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.008-750x422-e6b0a3.png&quot; width=&quot;750&quot; height=&quot;421&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 56.25%;&quot;&gt;&lt;img src=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.009-750x422-fb7d6b.png&quot; srcset=&quot;/images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.009-750x422-fb7d6b.png 562w, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.009-750x422-fb7d6b.png 562w 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.009-1500x842-fb7d6b.png 2x, /images/generated/prototyping-up-a-storm-realizing-the-stitch-interface/Dynabots_Prototype_Presentation_07212014.009-750x422-fb7d6b.png&quot; width=&quot;750&quot; height=&quot;421&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;We gained invaluable insight into these designs almost immediately, thanks to another meeting with Vince Ball from Nytec. Vince helped us work through some very different possibilities for the explore interface’s navigation controls, as well as some other options for the app’s information architecture. Conversations like these are what will help us iterate on our prototype designs with clear purpose and urgency.&lt;/p&gt;

&lt;p&gt;Similarly, a piece of feedback that emerged from our discussions with our mentors and instructors was the importance of Stitch’s &lt;em&gt;explore&lt;/em&gt; interface. While capture remains important, there are potentially multiple ways to capture these immersive 3-D scenes, making exploration and annotation of the environment the most novel and accessible features of the system. In light of this feedback and our short project development schedule, we realize we need to quickly iterate on our explore interface prototype to improve our ability to evaluate it.&lt;/p&gt;

&lt;p&gt;Hence, our goals for prototype evaluation are thus focused on three things right now:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Iterating on our explore interface with a slightly higher level of interactivity to improve our ability to evaluate it.&lt;/li&gt;
  &lt;li&gt;Taking the prototype out into the world to perform usability evaluations with everyday people who might end up using the app.&lt;/li&gt;
  &lt;li&gt;Examining the prototypes in detail through heuristic evaluation, with the help of our project mentors.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The big takeaway: stay tuned for (much) more on exploration.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/prototyping-up-a-storm-realizing-the-stitch-interface&quot;&gt;Prototyping Up a Storm - Realizing The Stitch Interface&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on July 23, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Stitch - A New Concept with A New Direction]]></title>
  <link>/blog/stich-a-new-concept-with-a-new-direction</link>
  <id>/blog/stich-a-new-concept-with-a-new-direction</id>
  <published>2014-07-08T00:00:00-07:00</published>
  <updated>2014-07-08T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;p&gt;After our meeting with Vince Ball at Nytec, we spent many hours developing a brand-new concept in response to our design question. We realized that a successful response, which removes the barrier between creation and consumption of journalism, should harness the power of &lt;strong&gt;citizen journalism at its best&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Now, what is citizen journalism, and what does it mean for it to be “at its best”? TED speaker &lt;a href=&quot;http://www.ted.com/talks/paul_lewis_crowdsourcing_the_news&quot;&gt;Paul Lewis’s 2011 TEDxThessaloniki talk&lt;/a&gt; shared a powerful and practical vision for a future of investigative journalism in which reporters activately &lt;strong&gt;motivate&lt;/strong&gt; and &lt;strong&gt;direct&lt;/strong&gt; everyday people to submit the source material needed to uncover the truth. This is a different view of crowdsourcing in which &lt;strong&gt;citizens &lt;em&gt;help&lt;/em&gt; reporters do their jobs&lt;/strong&gt; rather than replace reporters altogether.&lt;/p&gt;

&lt;p&gt;We began to wonder, &lt;strong&gt;what would a crowdsourced platform for immersive, expository content look like?&lt;/strong&gt; How could it enable reporters and readers to build up a living, immersive &lt;em&gt;coverage space&lt;/em&gt;, filled with captures, embedded content, and storytelling? How could it enable &lt;em&gt;faraway walkthroughs&lt;/em&gt;? How could it give context to readers’ eyewitness accounts of a scene? How could it change when and why articles are written in response to events and happenings in the world?&lt;/p&gt;

&lt;p&gt;These are all questions we are thinking about as we further develop our new concept: “Stitch”. We’ve prepared several storyboards describing “Stitch” in action, which you can view below.&lt;/p&gt;

&lt;div class=&quot;video-container vimeo&quot;&gt;&lt;iframe width=&quot;960&quot; height=&quot;540&quot; src=&quot;//player.vimeo.com/video/100335348?portrait=0&amp;amp;title=0&amp;amp;byline=0&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;h3 id=&quot;what-is-stitch&quot;&gt;What is “Stitch”?&lt;/h3&gt;

&lt;p&gt;“Stitch” is a platform that enables immersive exploration of the news through three-dimensional locations and content embedded within the space, contributed by journalists and readers alike. The platform gives publishers a powerful way to combine the best of professional and citizen journalism: readers can not only immerse themselves the very spaces where the news happens, but they can also use &lt;strong&gt;the depth cameras in their (future) smartphones and tablets&lt;/strong&gt; to seamlessly contribute their own captures to the space.&lt;/p&gt;

&lt;h3 id=&quot;what-kinds-of-content-end-up-in-a-stitch-environment&quot;&gt;What kinds of content end up in a “Stitch” environment?&lt;/h3&gt;

&lt;p&gt;In addition to 3D captures, journalists and readers may embed other media, such as video, photos, audio, or written text, at specific points in the space, thereby giving all reader contributions greater context in the target location. They may also create narrated walkthroughs of the space to highlight specific environment features or content. In this way, the “Stitch” environments also serve as a space to create new stories from contributed content.&lt;/p&gt;

&lt;h3 id=&quot;how-do-stitch-environments-fit-into-the-news&quot;&gt;How do “Stitch” environments fit into the news?&lt;/h3&gt;

&lt;p&gt;The 3D environments of “Stitch” would be a joint production between journalists and readers in the field, and can be populated in several ways:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As a response to a speculative piece, in which a publication would solicit and incentivize readers to submit their 3D captures, videos, photos, and eyewitness accounts to build up an exploration space for a story.&lt;/li&gt;
  &lt;li&gt;As a supplement to a published story, where readers would embed their own content, walkthroughs, and other content into an existing or entirely reader-contributed 3D environment.&lt;/li&gt;
  &lt;li&gt;As a wholly reader-contributed response to an event or happening, which would provide captures and eyewitness accounts from which the publisher may generate their own published stories and other coverage in reference to the 3D environment and the content embedded in it.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;who-benefits-from-stitch&quot;&gt;Who benefits from “Stitch”?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;“Stitch” benefits publishers&lt;/strong&gt; by giving them a powerful new storytelling tool, one which gives unprecedented presence and context to the news they already cover. It also enables them to leverage the contributions of readers around the world to help journalists and readers explore, experience, and capture places they cannot be. This new way to contextualize reader contributions within a physical space also lets journalists validate their own coverage and generate new coverage in response. Finally, the immersive nature of “Stitch” and its deep integration to the publisher’s existing web coverage gives readers a new experience that extends well beyond the snippets of coverage they see elsewhere online.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;“Stitch” benefits readers&lt;/strong&gt; by offering them a compelling and immersive experience of the news by virtually taking them on-location and letting them explore for themselves. Readers who are actually on-site—especially those in places where the publisher is not—are now empowered to contribute their own captures and experiences to an environment. Further, readers can receive rewards and incentives in exchange for their valuable contributions, such as access to more content on the publisher’s website. In this way, readers are invited as collaborators to get more involved in the work news-making.&lt;/p&gt;

&lt;h3 id=&quot;next-steps&quot;&gt;Next Steps&lt;/h3&gt;

&lt;p&gt;We’ve already begun to expand on our concept with these system component and interaction diagrams:&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/stich-a-new-concept-with-a-new-direction/IMG_7821-750x500-9291e4.JPG&quot; srcset=&quot;/images/generated/stich-a-new-concept-with-a-new-direction/IMG_7821-750x500-9291e4.JPG 562w, /images/generated/stich-a-new-concept-with-a-new-direction/IMG_7821-750x500-9291e4.JPG 562w 2x, /images/generated/stich-a-new-concept-with-a-new-direction/IMG_7821-1500x1000-9291e4.JPG 2x, /images/generated/stich-a-new-concept-with-a-new-direction/IMG_7821-750x500-9291e4.JPG&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/stich-a-new-concept-with-a-new-direction/IMG_7820-750x500-b034bd.JPG&quot; srcset=&quot;/images/generated/stich-a-new-concept-with-a-new-direction/IMG_7820-750x500-b034bd.JPG 562w, /images/generated/stich-a-new-concept-with-a-new-direction/IMG_7820-750x500-b034bd.JPG 562w 2x, /images/generated/stich-a-new-concept-with-a-new-direction/IMG_7820-1500x1000-b034bd.JPG 2x, /images/generated/stich-a-new-concept-with-a-new-direction/IMG_7820-750x500-b034bd.JPG&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;This week we are diving head-first into prototyping interfaces as well.&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;/blog/stich-a-new-concept-with-a-new-direction&quot;&gt;Stitch - A New Concept with A New Direction&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on July 08, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Nytec Meeting, New Ideas, and Back to Our Roots]]></title>
  <link>/blog/nytec-meeting-new-ideas-and-back-to-our-roots</link>
  <id>/blog/nytec-meeting-new-ideas-and-back-to-our-roots</id>
  <published>2014-07-03T00:00:00-07:00</published>
  <updated>2014-07-03T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;p&gt;Last week our team had a meeting with Vincent Ball from Nytec, one of our mentors for this project. We visited the Nytec studios and took a tour of their in-house usability and prototyping facilities. We presented some early concepts to Vince and had a very insightful discussion about the problem area of our project.&lt;/p&gt;

&lt;p&gt;The conversation we had with Vince steered our thoughts back towards some ideas we started thinking about early on in the capstone project. At the same time, it also helped us see how some parts of the concepts we had recently been working on needed to be relooked and reconsidered.  Some big insights came out in the course of the conversation, which we considered in the round of ideation that followed, and which has now culminated into a brand-new concept.&lt;/p&gt;

&lt;p&gt;Some of the questions we discussed: how can we leverage the 3D depth camera technology? How do we bring about additional value to content using this technology? What new possibilities are there when this camera technology is in everyday personal devices? This further got us thinking about how all this could change the way news content is created. &lt;strong&gt;What if depth camera technology and the right software enabled anyone to contribute to their own high-quality work to enhance the work of professional journalists?&lt;/strong&gt; This would be a fantastic opportunity to involve people in co-creation of content. In a way, this was us coming back closer to the design question we started out with: the focus on removing the barrier between creation and consumption of content.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/nytec-meeting-new-ideas-and-back-to-our-roots&quot;&gt;Nytec Meeting, New Ideas, and Back to Our Roots&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on July 03, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Journalism Focus Group]]></title>
  <link>/blog/focus_group</link>
  <id>/blog/focus_group</id>
  <published>2014-07-01T00:00:00-07:00</published>
  <updated>2014-07-01T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/focus_group/IMG_3835-750x500-5dd6f5.JPG&quot; srcset=&quot;/images/generated/focus_group/IMG_3835-750x500-5dd6f5.JPG 562w, /images/generated/focus_group/IMG_3835-750x500-5dd6f5.JPG 562w 2x, /images/generated/focus_group/IMG_3835-1500x1000-5dd6f5.JPG 2x, /images/generated/focus_group/IMG_3835-750x500-5dd6f5.JPG&quot; alt=&quot;focus group&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;july-1st-journalism-focus-group&quot;&gt;July 1st Journalism Focus Group&lt;/h3&gt;

&lt;p&gt;We had done a lot of secondary research about journalism, and even some primary research with news readers, but we had so far been unable to talk to any journalists. That all changed with our focus group exercise on Tuesday, We brought together an editor, a blogger, and three readers of both print and digital media. We asked the journalists what their perception of their readers were, how stories were chosen, and the value they get out of their work. We asked the readers about the perceived value they received from reading the news, and whether they would like to have more of a voice in the types of stories that were written. Finally, we asked both the journalists and readers about interactions between writers and readers, and their thoughts on digital vs print media. After that discussion ended, we asked the group to look at a couple of our early design concepts and give us feedback.&lt;/p&gt;

&lt;p&gt;Through this exercise, we not only got to practice running a focus group and the setup and assignment of team member responsibilities, we also gained valuable insight into how both readers and writers see the current publishing industry, and where they think it’s going. We got to learn about the reasons our group read certain publications over others, and that trust in the publication is a big theme. We also learned about the role that freelance journalists play in the news that is presented, and the perception around paying for news. Namely, that the interaction model around getting and reading the news might have to fundamentally change in order to persuade the people who currently read news for free to pay for it. Perhaps most importantly, we got feedback on our design concepts, which reinforced the idea that what people say they would like is not necessarily something they would use in reality.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/focus_group/IMG_7798-750x500-7148fb.JPG&quot; srcset=&quot;/images/generated/focus_group/IMG_7798-750x500-7148fb.JPG 562w, /images/generated/focus_group/IMG_7798-750x500-7148fb.JPG 562w 2x, /images/generated/focus_group/IMG_7798-1500x1000-7148fb.JPG 2x, /images/generated/focus_group/IMG_7798-750x500-7148fb.JPG&quot; alt=&quot;focus group&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;This focus group had a large impact on our future design work, because it reinforced some of our assumptions about the news, and tore down others. Many insightful and relevant quotes came out of that focus group, which we can use both to inform our future designs and to provide proof for our design rationale. We also gained a lot of value from showing the group our early design concepts, because getting feedback this early in our ideation process allows us more time to revisit those concepts and iterate on them, or come up with completely new concepts.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/focus_group&quot;&gt;Journalism Focus Group&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on July 01, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Ideation Session 1]]></title>
  <link>/blog/ideation_session_1</link>
  <id>/blog/ideation_session_1</id>
  <published>2014-06-27T00:00:00-07:00</published>
  <updated>2014-06-27T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;ideation-session-1&quot;&gt;Ideation Session 1&lt;/h3&gt;

&lt;p&gt;Today we met to start ideating design concepts for the first time. Keeping the research we did in mind, we started out by asking ourselves what we might need as a reader and as a journalist.&lt;/p&gt;

&lt;p&gt;As a Reader, we might want:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;To share our perspectives. Connect with authors.&lt;/li&gt;
  &lt;li&gt;To be able to get news from multiple angles and perspectives from around the globe&lt;/li&gt;
  &lt;li&gt;To know what I’m missing&lt;/li&gt;
  &lt;li&gt;To see where a piece of content might fall on the spectrum of different viewpoints, to help expose and see where my gaps are.&lt;/li&gt;
  &lt;li&gt;To be the actual ‘scene’ where the news was created; the notion of being in-the-moment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a Journalist/ Publisher:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We might want to know what readers want to read? What subjects interest them? what combination of local news and global is needed?&lt;/li&gt;
  &lt;li&gt;What to know about who is reading the content?&lt;/li&gt;
  &lt;li&gt;A better way for feedback, and communication with readers.&lt;/li&gt;
  &lt;li&gt;To be able to capture the actual ‘scene’, content and feeling of the place where news is created.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We discussed the importance of different Perspectives, and brainstormed several ideas about how to visualize this. Readers should be able to find multiple nuanced perspectives on a topic. They could have different level of immersion based upon distance from the device. There could possibly be a way to visualize readers’ consumption biases, and explore related perspectives. We could also show different content headlines or summaries based on the  physical orientation of the device, enabling a novel method of interaction.&lt;/p&gt;

&lt;p&gt;Lastly, we were not fully convinced about 3D gestures on a mobile phone, though we can see the depth camera in use for recognition and capture. &lt;/p&gt;

&lt;h3 id=&quot;concepts&quot;&gt;Concepts&lt;/h3&gt;

&lt;p&gt;The concepts are constantly evolving, here we present a snapshot of a few of the concepts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Flipping phone: Flips point of view on a story when you change the phone’s orientation. Shows only part of the new perspective initially so you can still orient yourself as to what you are reading. Recognizes topics from newspaper articles or what’s being watched on TV, and then pulls other similar article on the phone. Users can tilt the phone to reveal related article but written from a different perspective. It helps discovery, and going wide and deep into a topic, but would not necessarily get us to new topics.&lt;/li&gt;
  &lt;li&gt;Visualize how a story has progressed based on the context of user comments&lt;/li&gt;
  &lt;li&gt;Parallax interactions and infinite scroll in that a tablet acts more like a roll of paper&lt;/li&gt;
  &lt;li&gt;Perspective and scale (zooming in from space, Power of Ten video example)&lt;/li&gt;
  &lt;li&gt;3-way/funhouse mirror metaphor that could show you different perspectives on a story&lt;/li&gt;
  &lt;li&gt;Virtual tours that trigger information presentations to the reader based on how they view the tour at certain angles (tilting the device?)&lt;/li&gt;
  &lt;li&gt;3D video &lt;/li&gt;
  &lt;li&gt;Visualize where points of view in an article fall in a spectrum&lt;/li&gt;
  &lt;li&gt;Virtual product review desk&lt;/li&gt;
  &lt;li&gt;Origami is a  flexible, half analog, half digital newspaper with tessellations. It is low cost, but a robust and durable device. It tracks the shape of the paper(screen) and displays news according to the orientation and current shape. The shape can be changed by folding and unfolding it at certain locations. The device can be taken home and updated using a mobile phone.&lt;/li&gt;
  &lt;li&gt;News stand of the future - big wall where you can view the types of stories people have been viewing while in that location - trend visualization. This might be a communal wall of news. &lt;/li&gt;
  &lt;li&gt;Projecting 3D interactive content on a flat surface - uses in-air gestures to manipulate it&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From this exercise, we learned that we work best when we can visually communicate our ideas to each other, because it gives us something tangible to build on. It also lets us think about form factors and features. We also discovered that brainstorms don’t always have to be very structured. Sometimes an exercise that you planned to do during brainstorms doesn’t work out the way you wanted it to, and you have to be ready to let it go and try something else. For instance, we started out by thinking about how to come up with concepts around our design question, but didn’t come up with too many concepts, just design principles. These design principles ended up leading us to think about design concepts that might meet those principles, and that ended up being much more productive.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/ideation_session_1&quot;&gt;Ideation Session 1&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on June 27, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Project Plan Deliverable]]></title>
  <link>/blog/project_plan_deliverable</link>
  <id>/blog/project_plan_deliverable</id>
  <published>2014-06-26T00:00:00-07:00</published>
  <updated>2014-06-26T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 53.84615384615385%;&quot;&gt;&lt;a href=&quot;https://drive.google.com/file/d/0B-YvMLVHMKS6TEJyRld3ZVluU00/edit?usp=sharing&quot;&gt;&lt;img src=&quot;/images/generated/project_plan_deliverable/6-30%20Dynabots%20Detailed%20Task%20Plan%20Gantt%20Chart-750x404-e19fed.png&quot; srcset=&quot;/images/generated/project_plan_deliverable/6-30%20Dynabots%20Detailed%20Task%20Plan%20Gantt%20Chart-750x404-e19fed.png 562w, /images/generated/project_plan_deliverable/6-30%20Dynabots%20Detailed%20Task%20Plan%20Gantt%20Chart-750x404-e19fed.png 562w 2x, /images/generated/project_plan_deliverable/6-30%20Dynabots%20Detailed%20Task%20Plan%20Gantt%20Chart-1500x806-e19fed.png 2x, /images/generated/project_plan_deliverable/6-30%20Dynabots%20Detailed%20Task%20Plan%20Gantt%20Chart-750x404-e19fed.png&quot; width=&quot;750&quot; height=&quot;403&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;

&lt;p&gt;We decided to split the content of the project plan between us. Luckily, we already had a task plan in place, which made a lot of the work easier. We each took sections of the task plan to describe in more detail, as well as sections of the rest of the paper. This included things like what we wanted to accomplish with our future research, our target audience, and what we envisioned the outcome of the project to be.&lt;/p&gt;

&lt;p&gt;Looking back, having to think about resources for each task, as well as the reason for doing each task, was very helpful in focusing our future work goals and how to accomplish them. While this seems like an obviously good thing to do in most task planning exercises, there is nothing like having the first-hand experience of trying to accomplish a task and realizing you forgot something or that it didn’t have the outcome you were hoping for. At least this way we have a better idea of what we need to do in order to make progress on this capstone, and why. Creating this task plan also made us newly aware of deadlines and the amount of work each of us would have to contribute, in a good way. The task plan really gave us a physical reminder of our goals and the road ahead.&lt;/p&gt;

&lt;p&gt;The task plan also served to illustrate just how important clear tasks, goals, and deadlines are to the overall design process. We were able of separate sections of the task plan into stages of the design process, such as exploration and ideation or design and refinement. It also allowed us to see just how those stages transitioned, and the way in which the tasks of one stage affected the tasks in another stage.&lt;/p&gt;

&lt;p&gt;You can download and read the first revision of our project proposal here: &lt;a href=&quot;https://drive.google.com/file/d/0B-YvMLVHMKS6SDBEeHhyZmR4M3c/edit?usp=sharing&quot;&gt;6-30 Project Plan and Proposal.pdf&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/project_plan_deliverable&quot;&gt;Project Plan Deliverable&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on June 26, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Focus Group Planning and Feedback]]></title>
  <link>/blog/focus_group_planning_and_feedback</link>
  <id>/blog/focus_group_planning_and_feedback</id>
  <published>2014-06-25T00:00:00-07:00</published>
  <updated>2014-06-25T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activities-this-week&quot;&gt;Activities this week&lt;/h3&gt;

&lt;p&gt;This week we conducted a session of sharing some insights from a study we read about the experience of published content. We were battling with thoughts about what readers actually want that journalism today is lacking? What experience is lacking? On the other hand, what do journalists need to create better content? This also links back to some findings that came up when we did contextual interviews with The Daily, a publication at UW. An interesting thought came up during this conversation this week: &lt;/p&gt;

&lt;p&gt;“what if we put a journalist and a reader together and ask them to discuss their thoughts on consumption and creation of publishing content?”&lt;/p&gt;

&lt;p&gt;This triggered a realization that a focus group might be a good approach to answer some of these questions, give us a push in the right direction and see both sides of the story. We took this up as our next and final big research method before moving on to ideation. We plan to recruit three journalists (online only medium, traditional, professional blogger), an editor if we can access someone and three readers (a paid subscriber, free online news readers, and a blogger). We have identified a few potential participants that fall under these categories, our next task is to approach them and schedule the focus group. We plan to keep this focus group conversational with a facilitator initiating conversation. Below are examples of a few potential questions we have started planning out for this. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What are your perceptions of your readers? What value do you think they get from your content? What value should you receive? (to journalists)&lt;/li&gt;
  &lt;li&gt;How, if ever, do you interact with your readers? (to journalists)&lt;/li&gt;
  &lt;li&gt;How, if ever, do you interact with the writer? (to readers)&lt;/li&gt;
  &lt;li&gt;How do you decide on your pieces? Is this dictated by what readers want, or what your editors plan? (to journalists)&lt;/li&gt;
  &lt;li&gt;How do you feel about that? (to readers)&lt;/li&gt;
  &lt;li&gt;What do you think about digital vs. print? Give us examples (to both)&lt;/li&gt;
  &lt;li&gt;What do you feel would be helpful in creating/consuming? What do you want? (to both)&lt;/li&gt;
  &lt;li&gt;Initiate conversation with storyboards, example videos or some prototype.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As we started to plan this early user evaluation, we identified that a major challenge with this kind of a project is getting across such an experiential concept to the users at an early stage where it does not exist. Initially we thought of using storyboards of early concepts, however, modes of communication like storyboards might turn out to be too static for the kind of experience we want to convey. The challenge is finding an appropriate way to showcase the possibilities enabled by this technology to the users to get early feedback on desirability. This could mean showing examples of existing technologies to show what is possible, could be smoke and mirror prototypes or a video prototype. We have yet to plan that part. Conducting this focus group is a massive ambitious effort given our limited time frame, however, we believe it is one that will give us tremendous insight into the concept of collaborative co-creation between creators and consumers of content. We plan to conduct this mid-week next week. Today we went through the process of planning our recruitment of participants and setup for focus group. &lt;/p&gt;

&lt;p&gt;Apart from this we have a few upcoming expert interviews in the next week and an observation activity planned. &lt;/p&gt;

&lt;h3 id=&quot;other-thoughts-we-have-been-working-on--this-week&quot;&gt;Other Thoughts We Have been Working on  This Week&lt;/h3&gt;

&lt;p&gt;The following are a summary of internal conversations as well as our weekly feedback session with our capstone class coordinators.&lt;/p&gt;

&lt;p&gt;The problem with digital content right now is that it is not a conversation. It is very linear. What if consumption of content can be made into more of an interaction? What if we create a platform for collaborative co-creation and understanding of news? Co-creation of content between creators (journalists, bloggers, editors) and consumers of content could lead to a conversation which would make journalism much more richer. &lt;/p&gt;

&lt;p&gt;Thinking about journalism these days, something that keeps coming up is this notion of quality. What does quality mean exactly to people? Is quality the traditional perspective of journalism, i.e. ‘integrity’? Or is it becoming more about ‘understanding’? How does the experience of how the content is presented and consumed make the understanding of news better? &lt;/p&gt;

&lt;p&gt;These were just some thoughts that we want to further continue to think about as we move into ideation. As we start thinking about how to bridge our research into ideation, a good approach seems to be to develop our hypothesis on some of these overarching notions that we have been thinking about and come up with a few ideas for each.  In the next stages, we want to get into an intense phase of starting to build out ideas and test them out in various fidelity levels. The focus group will be a good final front-end research activity to push things forward into this upcoming phase.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/focus_group_planning_and_feedback&quot;&gt;Focus Group Planning and Feedback&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on June 25, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Affinity Mapping of the Secondary Research Done to Date]]></title>
  <link>/blog/affinity_mapping_of_the_secondary_research_done_to_date</link>
  <id>/blog/affinity_mapping_of_the_secondary_research_done_to_date</id>
  <published>2014-06-09T00:00:00-07:00</published>
  <updated>2014-06-09T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;Our team is really good at research. I mean, when I say, really good, I really mean it. We can go through tons and tons of articles in matter of a couple of days. But what happens next? Where can we go from there? How do all these individual pieces of knowledge contribute to the bigger picture of project? With hundred of notes in our Mendeley Account, we were starting to think we will never be able to effectively realize the value of research we have done. However, with our dedication to using the best practices in the design and research process, we decided to try an Affinity Mapping Exercise—a method that Karen Holtzblatt (InContext Design) puts so much emphasis on as a primary method of consolidating research findings.&lt;/p&gt;

&lt;p&gt;We started by individually going through the papers we had read, summarizing the highlights on Post-Its and explaining them to the other team members as they put the Post-It on the board. We filled out multiple whiteboards and got kicked out of two different libraries because they were closing. In the end, we had identified major themes on our Post-Its and had started to categorize them into those themes (clusters). We then did a pass through the information on the board, eliminating redundant facts and pieces of information that were way outside of our scope or irrelevant to our current direction.&lt;/p&gt;

&lt;p&gt;Having organized our Post-Its into clusters, we then started to find connections and overlays between the different clusters. Specifically, we worked to establish relationships between the clusters of 3D gesture technologies and the clusters of publishing industry information.&lt;/p&gt;

&lt;p&gt;With two giant whiteboards full of information, we had managed to boil down and categorize our research findings into clusters that we could work to dig deeper or dismiss as irrelevant to our current focus.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 27.169459962756054%;&quot;&gt;&lt;a href=&quot;https://drive.google.com/file/d/0B-YvMLVHMKS6TkZ1YVhBWnFMMUU/edit?usp=sharing&quot;&gt;&lt;img src=&quot;/images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram%20Pano%20Ninja-750x204-96e92a.jpg&quot; srcset=&quot;/images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram%20Pano%20Ninja-750x204-96e92a.jpg 562w, /images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram%20Pano%20Ninja-750x204-96e92a.jpg 562w 2x, /images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram%20Pano%20Ninja-1500x406-96e92a.jpg 2x, /images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram%20Pano%20Ninja-750x204-96e92a.jpg&quot; width=&quot;750&quot; height=&quot;203&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;

&lt;h3 id=&quot;activity-findings&quot;&gt;Activity Findings&lt;/h3&gt;

&lt;p&gt;We formed groups around problems, types, and properties of gesture technology; print and digital media; mobile platforms; content delivery; storytelling platforms; the focus of media coverage; user-contributed content; revenue and advertising; business models; audience; inter-business sharing of content; and social sharing. After looking at these groups, we felt that there were opportunities in the following areas:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The intersection of social-sharing, storytelling platforms, reader-generated content, and gesture technology&lt;/li&gt;
  &lt;li&gt;Relationships between print media, digital media, and the changing focus of coverage &lt;/li&gt;
  &lt;li&gt;Consumers, news media, and content creation (from stakeholder map)
For better access and retrieval of this valuable research artifact, we decided to digitize this big diagram using OmniGraffle. Below is the digital version of our affinity diagram.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 80.59869457573711%;&quot;&gt;&lt;a href=&quot;https://drive.google.com/file/d/0B-YvMLVHMKS6QlRlODhIR1FZQ3c/edit?usp=sharing&quot;&gt;&lt;img src=&quot;/images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram-750x604-bf56b9.jpg&quot; srcset=&quot;/images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram-750x604-bf56b9.jpg 562w, /images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram-750x604-bf56b9.jpg 562w 2x, /images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram-1500x1208-bf56b9.jpg 2x, /images/generated/affinity_mapping_of_the_secondary_research_done_to_date/Giant%20Affinity%20Diagram-750x604-bf56b9.jpg&quot; width=&quot;750&quot; height=&quot;604&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;

&lt;h3 id=&quot;implications-for-design&quot;&gt;Implications for Design&lt;/h3&gt;

&lt;p&gt;Having concluded our primary phase of secondary research, we are planning on using this diagram as a useful way of determining and guiding our primary research activities. Furthermore, having a consolidated source of current trends, information, and technology has helped us greatly in achieving a common mental model and understanding of the problem space we are working with.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/affinity_mapping_of_the_secondary_research_done_to_date&quot;&gt;Affinity Mapping of the Secondary Research Done to Date&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on June 09, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[The Mobile Intervention]]></title>
  <link>/blog/the_mobile_intervention</link>
  <id>/blog/the_mobile_intervention</id>
  <published>2014-06-05T00:00:00-07:00</published>
  <updated>2014-06-05T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 56.41025641025641%;&quot;&gt;&lt;img src=&quot;/images/generated/the_mobile_intervention/heuristic%20evaluation%20flipboard-750x423-0aab40.jpg&quot; srcset=&quot;/images/generated/the_mobile_intervention/heuristic%20evaluation%20flipboard-750x423-0aab40.jpg 562w, /images/generated/the_mobile_intervention/heuristic%20evaluation%20flipboard-750x423-0aab40.jpg 562w 2x, /images/generated/the_mobile_intervention/heuristic%20evaluation%20flipboard-1500x846-0aab40.jpg 2x, /images/generated/the_mobile_intervention/heuristic%20evaluation%20flipboard-750x423-0aab40.jpg&quot; alt=&quot;Fipboard screenshot&quot; width=&quot;750&quot; height=&quot;423&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;From our ongoing secondary research, it was evidently clear that revenue earned by ads on print media is declining, and that many well-known people in the print industry have started or have already transitioned to the digital news industry. But, what is more interesting is that this transition has been catalyzed by the introduction of smart phones. Smartphones are can mostly be categorized as always available devices, which can be easily used between two activities and are non intrusive. They can easily fill in any free gaps between two activities. The ubiquitous and low barrier in consuming content using a smartphone proved more fatal for the traditional print media. To gain further insights around this topic we first gathered observations from various sources such as the Pew Research and others, and plotted an affinity diagram.&lt;/p&gt;

&lt;h3 id=&quot;what-does-that-mean&quot;&gt;What Does that Mean?&lt;/h3&gt;

&lt;p&gt;The key insight was that news media content is increasingly being read on mobile devices, regardless of the medium it’s in and moreover mobile consumption is becoming more and more popular. Furthermore, we discovered that age group plays a part in the amount of mobile consumption. Pew Research Center Project has found that more young people consume news online, especially women, and that women in the age group of 25 to 49 consumed the most content on smartphones.&lt;/p&gt;

&lt;p&gt;However, the shift to online and mobile news consumption has also started to change not just the medium of news consumption, but also the behavior of readers consuming the news. Pew Research found that young people are more likely to “graze” the news, which means that they do not read or watch news at a set time of day as older generations used to. Research has also shown that mobile readers are more likely to read headlines on mobile, but usually wait until they are on a tablet or desktop computer to read the full article.&lt;/p&gt;

&lt;h3 id=&quot;implications-for-design-and-moving-forward&quot;&gt;Implications for Design and Moving Forward&lt;/h3&gt;

&lt;p&gt;These insights tell us that we need to be aware of different age groups in our design, as well as the likelihood of developing a mobile solution. We might also want to research novel mobile interactions.&lt;/p&gt;

&lt;p&gt;These insights reiterate the probable importance of mobile in our future research and design activities. If the trend is truly heading towards cursory reading on mobile, we also need to research the advertiser’s role on mobile platforms, especially native ads. Also, Ad revenue from subtle ads may become even more important if the reader’s attention span is short. &lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;/blog/the_mobile_intervention&quot;&gt;The Mobile Intervention&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on June 05, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Expert Interview with Scott Saponas]]></title>
  <link>/blog/expert_interview_with_scott_saponas</link>
  <id>/blog/expert_interview_with_scott_saponas</id>
  <published>2014-06-05T00:00:00-07:00</published>
  <updated>2014-06-05T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;Early this June we conducted an expert interview with T. Scott Saponas at Microsoft Research. Scott’s expertise in Human Computer Interaction, specifically with experimental input and output technologies and always-available, context-aware computing, seemed like a useful resource for our project as we explore potential ways of interaction with media. The interview was a good way to quickly gain insight into the field of input and gesture technology and supplement what we found through secondary and some primary research that we previously did. We had several questions for him:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What types of interactions are harder to do with 3D gestures and why?&lt;/li&gt;
  &lt;li&gt;How do 3D gestures make certain interactions easier and why?&lt;/li&gt;
  &lt;li&gt;What do you see as the future of 3D gesture interfaces?&lt;/li&gt;
  &lt;li&gt;How might spatial sensing change our daily interactions with personal devices?
Specifically, how might this change how we consume content on these devices?&lt;/li&gt;
  &lt;li&gt;How do you think media content could be made context-aware?&lt;/li&gt;
  &lt;li&gt;What media types would actually feel compelling to interact with or consume using new
input techniques?&lt;/li&gt;
  &lt;li&gt;What could 3D interactions with media give us that current media does not?&lt;/li&gt;
  &lt;li&gt;What content could be created with context-aware input and interfaces?&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.48936170212765%;&quot;&gt;&lt;img src=&quot;/images/generated/expert_interview_with_scott_saponas/scott-750x499-668351.jpg&quot; srcset=&quot;/images/generated/expert_interview_with_scott_saponas/scott-750x499-668351.jpg 562w, /images/generated/expert_interview_with_scott_saponas/scott-750x499-668351.jpg 562w 2x, /images/generated/expert_interview_with_scott_saponas/scott-1500x996-668351.jpg 2x, /images/generated/expert_interview_with_scott_saponas/scott-750x499-668351.jpg&quot; alt=&quot;Scott Saponas&quot; width=&quot;750&quot; height=&quot;498&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;key-findings-and-takeaway&quot;&gt;Key Findings and Takeaway&lt;/h3&gt;

&lt;p&gt;Outlined below are some of the key insights we got from the interview.&lt;/p&gt;

&lt;h4 id=&quot;challenges-of-3d-gestures&quot;&gt;Challenges of 3D Gestures&lt;/h4&gt;

&lt;p&gt;We got valuable insights into challenges and considerations in designing for systems that use 3D manipulation and gestures from this conversation. Interactions with 3D gestures are hard because we are used to the idea of direct manipulation with a mouse or touch screen. On the system’s end, it is hard to interpret intentions and separate gestures from other movements. Furthermore, for gesture input and 3D manipulation, the gulf of evaluation is harder to bridge than the gulf of execution. Immediate response and feedback on the input is very important. It becomes really hard when the feedback loop is broken or is very slow. A major advantage of 3D interaction is unanchored interaction. The fact that whatever you are using to manipulate is not physically anchored to the device opens up a lot of possibilities for both design and potential problems simultaneously.&lt;/p&gt;

&lt;h4 id=&quot;designing-for-3d-gestures&quot;&gt;Designing for 3D Gestures&lt;/h4&gt;

&lt;p&gt;The key is to design the system around an assumption that tasks will afford experimentation and that errors are inherent. The system needs to be designed for better error correction such that the possible errors are not that critical. The penalty for wrong/inaccurate input should be low. Responsiveness is another important thing to keep in mind.&lt;/p&gt;

&lt;h4 id=&quot;spatial-sensing-and-future&quot;&gt;Spatial Sensing and Future&lt;/h4&gt;

&lt;p&gt;The most powerful and transformative thing about spatial sensing is that it enables the ability
to import personal space into a computer simulation system; capturing the real world and
transferring it to others. Scott believes people will likely pay a lot for that and this will likely be a big change in sensor use on phones in the future. There are possible applications of such technology in retail, consulting businesses, and service design.&lt;/p&gt;

&lt;h4 id=&quot;new-media-forms-enabled-by-input-technology&quot;&gt;New Media Forms Enabled by Input Technology&lt;/h4&gt;

&lt;p&gt;Scott mentioned 3D manipulation and augmented reality are two compelling areas to explore. With new forms of interaction like depth cameras, precise control is going to be hard, but he believes these can be very engaging if you incorporate tactile interaction and enable physical manipulation.&lt;/p&gt;

&lt;h4 id=&quot;how-content-and-media-needs-to-evolve&quot;&gt;How Content and Media Needs to Evolve&lt;/h4&gt;

&lt;p&gt;In Scott’s opinion, even though technology has changed a lot, the media we consume hasn’t
evolved much in the last few years. There should be ways to interact with what we are
consuming. Everything is currently linear. Future of media should be interactive and two -
directional, not linear. A good, simple example is the ability to change the camera angle on a
movie to discover more about the space and immerse yourself in it.&lt;/p&gt;

&lt;h3 id=&quot;implications-for-design-and-moving-forward&quot;&gt;Implications for Design and Moving Forward&lt;/h3&gt;

&lt;p&gt;We got a great deal of insight out of our conversation with Scott. Among other things, Scott confirmed our hunch that new forms of interactive media could be very critical to affecting real change in the publishing space. Also, Scott pushed the idea that gesture interfaces can trade precision for exploration, which is a powerful restraint that can help us avoid gestural interface designs that require a level of accuracy that simply isn’t attainable.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/expert_interview_with_scott_saponas&quot;&gt;Expert Interview with Scott Saponas&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on June 05, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Devising a Stakeholder Map]]></title>
  <link>/blog/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space</link>
  <id>/blog/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space</id>
  <published>2014-06-05T00:00:00-07:00</published>
  <updated>2014-06-05T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;We chose to do a stakeholder map because we wanted to better understand the relationships between the stakeholders and how value passes between them. More specifically, we wanted to see what values in addition to money were passing between stakeholders. We started by writing all the stakeholders we could think of on post-it notes. Once that was finished, we grouped related post-it notes on a large sheet of butcher paper. When we had managed to group all of the post-it notes, we came up with overarching group titles for each cluster of stakeholders. The main groups were determined to be publishing platforms, consumers, content creators, platform providers, and funders. The final step was to determine how value passed between the large groups of stakeholders as well as between individual stakeholders.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;a href=&quot;https://drive.google.com/file/d/0B-YvMLVHMKS6YlZVbURnVW0wRTQ/edit?usp=sharing&quot;&gt;&lt;img src=&quot;/images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/Stakeholder%20Map%20Photo-750x563-bdb494.jpg&quot; srcset=&quot;/images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/Stakeholder%20Map%20Photo-750x563-bdb494.jpg 562w, /images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/Stakeholder%20Map%20Photo-750x563-bdb494.jpg 562w 2x, /images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/Stakeholder%20Map%20Photo-1500x1124-bdb494.jpg 2x, /images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/Stakeholder%20Map%20Photo-750x563-bdb494.jpg&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;

&lt;h3 id=&quot;key-observations-and-takeaways&quot;&gt;Key Observations and Takeaways&lt;/h3&gt;

&lt;p&gt;Looking back, this exercise was a little surprising in how similar to an affinity diagram it turned out to be. Instead of research insights, we had stakeholders, and instead of themes, we had stakeholder groups. One of the challenges we had with this exercise was actually determining the difference between content creators and consumers. In one sense, the news media companies and employees were the main content creators, but news consumers could leave comments on that content, or start debates about the content among friends. Hence, consumers became somewhat of a secondary content creator. In the end, we decided that the comments and debates were one way that consumers passed value back to the media companies.&lt;/p&gt;

&lt;p&gt;This exercise was also successful because the entire team was contributing to it at the same time. We all came up with stakeholders and agreed on groupings and relationships, which helped to get us all on the same page and see the big picture. We had also decided to set a 20 minute time limit on this exercise in light of our remaining tasks at the time, and were able to successfully complete the stakeholder map in this timeframe. Consequently, we discovered that time limits in certain situations can help us to make decisions and be more efficient with our time.&lt;/p&gt;

&lt;p&gt;One additional takeaway came out of our effort to create a digital illustration of our stakeholder map. Creating this illustration gave us a chance to follow graphic design principles, resulting in better organization, better visual enclosure of the groups, and neatly drawn and labelled interactions between stakeholders. Our program director and others felt that all these improvements greatly added to their comprehension of the map. We found the illustrated version to be much more useful to us as well, so it’s likely that we’ll be doing many more “cleaned up” versions of our frameworking in the future.&lt;/p&gt;

&lt;h3 id=&quot;implications-for-design-and-moving-forward&quot;&gt;Implications for Design and Moving Forward&lt;/h3&gt;

&lt;p&gt;The creation of the stakeholder map ultimately helped us to see how the different stakeholder groups rely on each other, and what they expect from each other in terms of value. For instance, we determined that the content creators relied on funders such as advertisers for revenue, which allowed them to present content to consumers and (hopefully) turn a number of those consumers into subscribers, who would in turn create more revenue for the content creators. This map also allowed us to discover that many of the relationships between stakeholders are complex, which in turn helped us to narrow which relationships we wanted to focus on for our next steps. At the end of the exercise, we had decided to focus on the relationship between content creators and consumers. This focus led us to come up with a tentative design question, and will serve to narrow our future research and prototyping activities.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 89.3359375%;&quot;&gt;&lt;a href=&quot;https://drive.google.com/file/d/0B6G9Dt0S6FrqSm4wNi1ZcmFHRlU/edit?usp=sharing&quot;&gt;&lt;img src=&quot;/images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/stakeholders+mediaindustry2-750x670-6e1840.png&quot; srcset=&quot;/images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/stakeholders+mediaindustry2-750x670-6e1840.png 562w, /images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/stakeholders+mediaindustry2-750x670-6e1840.png 562w 2x, /images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/stakeholders+mediaindustry2-1500x1340-6e1840.png 2x, /images/generated/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space/stakeholders+mediaindustry2-750x670-6e1840.png&quot; width=&quot;750&quot; height=&quot;670&quot; /&gt;&lt;/a&gt;&lt;/figure&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/devising_a_stakeholder_map_in_20_minutes__connecting_the_dots_between_the_key_players_in_the_problem_space&quot;&gt;Devising a Stakeholder Map&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on June 05, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[A marginally better World of Publishing]]></title>
  <link>/blog/a_marginally_better_world_of_publishing</link>
  <id>/blog/a_marginally_better_world_of_publishing</id>
  <published>2014-06-05T00:00:00-07:00</published>
  <updated>2014-06-05T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;process-and-activity&quot;&gt;Process and Activity&lt;/h3&gt;

&lt;p&gt;If you think about the wide range of published content out there on the Internet, you might end up, like we did, with a collection of three archetypal points on a continuum:&lt;/p&gt;

&lt;p&gt;The typically high-quality, but often “linear” or “one-sided” work coming from in-house teams of writers and editors at “professional” news media outlets.
New forms of “clickbait” journalism, coming from contributor platforms such as Forbes and Business Insider, the quality of which can be pretty middling at times.
The diverse and occasionally insufficient world of user-generated journalism on the web, from blog posts to Internet comments.&lt;/p&gt;

&lt;p&gt;Now, if you’re not feeling too good about the future of journalism, you might look at these points and graph them quite pessimistically onto into a “death spiral” of declining journalistic quality, as we’ve done below:&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 56.25%;&quot;&gt;&lt;img src=&quot;/images/generated/a_marginally_better_world_of_publishing/Dynabots%20Capstone%20Project%20Introduction%20Video%20Slide%20Deck-750x422-1183b6.jpg&quot; srcset=&quot;/images/generated/a_marginally_better_world_of_publishing/Dynabots%20Capstone%20Project%20Introduction%20Video%20Slide%20Deck-750x422-1183b6.jpg 562w, /images/generated/a_marginally_better_world_of_publishing/Dynabots%20Capstone%20Project%20Introduction%20Video%20Slide%20Deck-750x422-1183b6.jpg 562w 2x, /images/generated/a_marginally_better_world_of_publishing/Dynabots%20Capstone%20Project%20Introduction%20Video%20Slide%20Deck-1500x842-1183b6.jpg 2x, /images/generated/a_marginally_better_world_of_publishing/Dynabots%20Capstone%20Project%20Introduction%20Video%20Slide%20Deck-750x422-1183b6.jpg&quot; width=&quot;750&quot; height=&quot;421&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;Now, that’s pretty gloomy, but it brings up another interesting point: this simple chart also describes something of a “trickle-down” model of derivative creative works. That is, readers comments on a “clickbait” article which sources information from a “professional” news report are all interconnected, in the end.&lt;/p&gt;

&lt;p&gt;We don’t have an answer for “what” or “how” yet, but considering this model of journalism, a rising tide raises all boats, right? Could some new form of content elevate the quality of the entire system? Maybe it’s possible—for all we know, there’s A Marginally Better World for journalism waiting out there for us.&lt;/p&gt;

&lt;h3 id=&quot;key-findings-and-observations&quot;&gt;Key Findings and Observations&lt;/h3&gt;

&lt;p&gt;Among all the other research and frameworking we’d done, this concept of journalistic quality inspired us to take the plunge into crafting a design question for our project. After many, many iterations, we finally hammered one out:&lt;/p&gt;

&lt;p&gt;How can we use new forms of interactive content to remove the barrier between creation and consumption of high-integrity, valuable journalism?&lt;/p&gt;

&lt;p&gt;Now, design questions serve two purposes: to give a project direction and focus, and to be endlessly picked apart, piece by tiny semantic piece. To bring some sanity to the latter activity, we qualified what we mean by “high-integrity” and “valuable journalism”:&lt;/p&gt;

&lt;p&gt;“High-Integrity” means that the content that has been researched, fact-checked, and edited; it is above the quality and accuracy of random comments and blog posts on the Internet.&lt;/p&gt;

&lt;p&gt;“Valuable Journalism” refers to content that provides something more stimulating than a simple “listicle”, and is capable of evoking thoughtful debates and critical thinking.&lt;/p&gt;

&lt;p&gt;Depending on who you ask, these may well be the primary tenets of “true” journalism itself, and as such, we feel the need to support high standards for quality and integrity as much as possible through our work.&lt;/p&gt;

&lt;h3 id=&quot;implications-for-design-and-project-next-steps&quot;&gt;Implications for Design and Project Next Steps&lt;/h3&gt;

&lt;p&gt;Where do we go from here?
Taking up the mantle of journalistic integrity is no easy feat, to be sure. To us, that means looking at media content through the lens of journalists: what can we do to help them produce great work? At the same time, there’s this possibility of elevating the quality of user-generated content: could there exist a system that could helps “consumers” create content that more powerfully enriches the source material? We don’t know yet, but this is a guiding principle, just like our principles of 3D gestural interfaces, that will serve us well as we begin to develop design concepts.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/a_marginally_better_world_of_publishing&quot;&gt;A marginally better World of Publishing&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on June 05, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Ideation To Guide Research]]></title>
  <link>/blog/ideation_to_guide_research_what_do_you_do_when_the_research_area_is_too_vast</link>
  <id>/blog/ideation_to_guide_research_what_do_you_do_when_the_research_area_is_too_vast</id>
  <published>2014-05-29T00:00:00-07:00</published>
  <updated>2014-05-29T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;p&gt;What happens when the area you are approaching is too vast to even know which part you are want to research? How do you narrow down your research areas, so that the research you do is effective and meaningful? After all, none of us likes to read tons of academic articles for no purpose!&lt;/p&gt;

&lt;p&gt;We were given a wide topic area: &lt;strong&gt;3D Gestures and Digital Publication.&lt;/strong&gt; Ok, So now what? Where do we start? We started by general term queries, and soon realized there was too much diversity to be able to conduct the research with general term queries. So, we decided to do an ideation session within the research. In a way, we decided to do an affinity diagram of the potential research paths we could take, to be able to focus our research.&lt;/p&gt;

&lt;p&gt;We started with the theme of “Experience of 3D Published Content”, and then began to define it.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 44.50298559887601%;&quot;&gt;&lt;img src=&quot;/images/generated/ideation_to_guide_research_what_do_you_do_when_the_research_area_is_too_vast/Experience%20of%203D%20Published%20Content%20Panorama-750x334-dff355.JPG&quot; srcset=&quot;/images/generated/ideation_to_guide_research_what_do_you_do_when_the_research_area_is_too_vast/Experience%20of%203D%20Published%20Content%20Panorama-750x334-dff355.JPG 562w, /images/generated/ideation_to_guide_research_what_do_you_do_when_the_research_area_is_too_vast/Experience%20of%203D%20Published%20Content%20Panorama-750x334-dff355.JPG 562w 2x, /images/generated/ideation_to_guide_research_what_do_you_do_when_the_research_area_is_too_vast/Experience%20of%203D%20Published%20Content%20Panorama-1500x666-dff355.JPG 2x, /images/generated/ideation_to_guide_research_what_do_you_do_when_the_research_area_is_too_vast/Experience%20of%203D%20Published%20Content%20Panorama-750x334-dff355.JPG&quot; alt=&quot;Experience of 3D Published Content Whiteboard Chart&quot; width=&quot;750&quot; height=&quot;333&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;What do we mean by experience? We defined it as feeling that you are in the action. You are part of the content you are consuming.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3D:&lt;/strong&gt; Why do we even need 3D? What value does 3D content add to our content?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Published:&lt;/strong&gt; what kind of publishing pattern and mode are we interested in? Daily, weekly, or monthly? Explanatory or Investigatory?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Content:&lt;/strong&gt; What type of content are we talking about? Are we referring to 3D text content? (Hope not, ‘cause that would be dizzying!), How about images. videos, and objects?&lt;/p&gt;

&lt;p&gt;Then we started writing out all the content types, varieties, topics, and manipulation techniques that we thought would be interesting or meaningful if delivered within a 3D medium. Furthermore, along with each Post-It that a team member put up, we explained why it would be a good idea to have that content in 3D. In a way, we started thinking about all the different ways 3D could be used. Even how people would be able to interact with their pets from a distance! &lt;/p&gt;

&lt;p&gt;Next, we decided to arrange our suggestions in clusters(themes), and tried to find connections between the the different clusters.   What resulted from this exercise was certain defined paths that we could now take in furthering our research. For example, some of our clusters were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Long lived (longer shelf life than newspapers, like magazines)&lt;/li&gt;
  &lt;li&gt;Social Collaboration and Sharing&lt;/li&gt;
  &lt;li&gt;Explorations in space and time&lt;/li&gt;
  &lt;li&gt;3D Visualization as an added layer of information for content communication&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What came out of this exercise? Clarity on how to pursue our research from here. We decided on pursuing three main topic areas:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Can 3D visualization be an additional layer of meaningful data for object and/or space exploration?&lt;/li&gt;
  &lt;li&gt;What experience does the publisher want to deliver?&lt;/li&gt;
  &lt;li&gt;What experiences do people expect from publishers? Does it match the experience that the publishers want to deliver?&lt;/li&gt;
&lt;/ol&gt;


  &lt;p&gt;&lt;a href=&quot;/blog/ideation_to_guide_research_what_do_you_do_when_the_research_area_is_too_vast&quot;&gt;Ideation To Guide Research&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on May 29, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Contextual Interview at The Daily]]></title>
  <link>/blog/contextual_interview_at_the_daily</link>
  <id>/blog/contextual_interview_at_the_daily</id>
  <published>2014-05-29T00:00:00-07:00</published>
  <updated>2014-05-29T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;process-and-activity&quot;&gt;Process and Activity&lt;/h3&gt;

&lt;p&gt;As we found from our secondary research, the publishing space is vast and filled with many unsolved problems. With more print publishers starting to integrate a digital presence, there is  a need to continue producing quality journalism, increase consumer engagement, integrate new technologies, and discover new, successful business models. Furthermore, our research revealed that in addition to platforms and methods of consumption of news and media, the type of news content is also changing. Additionally, on the ideation side, we were starting to also look at content creation as a possible direction in addition to how content is consumed. We figured that a good way to dig into this space effectively was to start talking to publishers. For this we chose to do contextual interviews at The Daily, a student run newspaper at the University of Washington, Seattle. We visited their newsroom during peak activity hours of 9-11 PM and spoke to their Editor-in-Chief, Content Editor and Arts Editor.&lt;/p&gt;

&lt;p&gt;Moreover, we thoroughly observed the workflow at the The Daily, which we noticed was very complex. There was a lot of back and forth exchange of content and media between writers, editors, designers and photographers. They currently use multiple tools, and in some cases have to use different sharing platforms for different types of media. This further adds to the complexity. A better collaborative system would be more supportive of this complicated exchange and editing process.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 45.54597701149425%;&quot;&gt;&lt;img src=&quot;/images/generated/contextual_interview_at_the_daily/IMG_2186%20(Best%20Panorama)-750x342-7c7168.JPG&quot; srcset=&quot;/images/generated/contextual_interview_at_the_daily/IMG_2186%20(Best%20Panorama)-750x342-7c7168.JPG 562w, /images/generated/contextual_interview_at_the_daily/IMG_2186%20(Best%20Panorama)-750x342-7c7168.JPG 562w 2x, /images/generated/contextual_interview_at_the_daily/IMG_2186%20(Best%20Panorama)-1500x682-7c7168.JPG 2x, /images/generated/contextual_interview_at_the_daily/IMG_2186%20(Best%20Panorama)-750x342-7c7168.JPG&quot; alt=&quot;Newsroom at The Daily&quot; width=&quot;750&quot; height=&quot;341&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.69135802469135%;&quot;&gt;&lt;img src=&quot;/images/generated/contextual_interview_at_the_daily/IMG_4313-750x560-375b5e.JPG&quot; srcset=&quot;/images/generated/contextual_interview_at_the_daily/IMG_4313-750x560-375b5e.JPG 562w, /images/generated/contextual_interview_at_the_daily/IMG_4313-750x560-375b5e.JPG 562w 2x, /images/generated/contextual_interview_at_the_daily/IMG_4313-1500x1120-375b5e.JPG 2x, /images/generated/contextual_interview_at_the_daily/IMG_4313-750x560-375b5e.JPG&quot; alt=&quot;Newsroom at The Daily&quot; width=&quot;750&quot; height=&quot;560&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/contextual_interview_at_the_daily/IMG_20140528_212011-750x563-5e0fb8.jpg&quot; srcset=&quot;/images/generated/contextual_interview_at_the_daily/IMG_20140528_212011-750x563-5e0fb8.jpg 562w, /images/generated/contextual_interview_at_the_daily/IMG_20140528_212011-750x563-5e0fb8.jpg 562w 2x, /images/generated/contextual_interview_at_the_daily/IMG_20140528_212011-1500x1124-5e0fb8.jpg 2x, /images/generated/contextual_interview_at_the_daily/IMG_20140528_212011-750x563-5e0fb8.jpg&quot; alt=&quot;Newsroom at The Daily&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;key-findings-and-observations&quot;&gt;Key Findings and Observations&lt;/h3&gt;

&lt;p&gt;It was apparent that they were aware of the need to work towards integrating interactivity and moving more toward their digital platform, however, access to the required resources and expertise seem to be a deterrent. The usefulness of a seamless way of integrating media and interactive elements like audio, video, slideshows etc also came up as we spoke to the editors. In terms of comparing their digital vs. print presence, surprisingly, we found that print is still their first priority and most stories - with the exception of breaking news stories that need an immediate push - are published for print and converted to the digital version with additional content as a later step. However, they do maintain an active digital presence on social media websites like Facebook and Twitter and have an iPad app. Interestingly, their statistics showed that their homepage gets low views because for the online content, most page visits occur via social media links which point straight to articles. This is interesting because it starts to show how social media changes the way news is consumed.&lt;/p&gt;

&lt;h3 id=&quot;implications-for-design-and-project-next-steps&quot;&gt;Implications for Design and Project Next Steps&lt;/h3&gt;

&lt;p&gt;What came out of this study encouraged us to dig deeper into the publishing industry, its shift from print to digital and the effect of social media and new forms of media. As a next step we did a thorough review and analysis of the Pew Research Center’s Journalism Project on the State of the News Media 2014.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/contextual_interview_at_the_daily&quot;&gt;Contextual Interview at The Daily&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on May 29, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[A Competitive Look at the Media Industry]]></title>
  <link>/blog/a_competitive_look_at_the_media_industry</link>
  <id>/blog/a_competitive_look_at_the_media_industry</id>
  <published>2014-05-29T00:00:00-07:00</published>
  <updated>2014-05-29T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;While researching the publishing industry for our capstone project, we started thinking:&lt;/p&gt;

&lt;p&gt;Okay, we know about all these different publishers, from newspapers to cable networks, but what different kinds of media are they producing, and at what frequency? Weekly? Daily? Hourly? What’s that space look like, and where are there gaps? Where do we think we can contribute?&lt;/p&gt;

&lt;p&gt;Mapping our knowledge of the publishing industry proved to be a challenge, especially as we constructed two different axes for our visualization. We’d been thinking a lot about present and future content experiences a while before, so we developed a vertical &lt;strong&gt;“media type”&lt;/strong&gt; axis with different “notches” corresponding to content such as text, photos, static graphics, all the way up to multimedia such as video, movies, and even virtual reality environments.&lt;/p&gt;

&lt;p&gt;From there, the horizontal axis fell into place: we realized it should represent “publishing frequency”. Together the two axes let us visually represent a wide range of content, from hourly Twitter posts, to weekly magazine issues, to yearly documentary productions.&lt;/p&gt;

&lt;p&gt;Here’s where the chart started getting a little crazy: no one publishing company really has a single niche in this space anymore! Even a “traditional” publisher like The New York Times has a web presence with blogs and video content, for example. Hence, we drew a handful of publishers on the chart as “ribbons” to depict the range of content types and publishing frequencies they typically cover.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/a_competitive_look_at_the_media_industry/IMG_7310-750x500-29a72e.JPG&quot; srcset=&quot;/images/generated/a_competitive_look_at_the_media_industry/IMG_7310-750x500-29a72e.JPG 562w, /images/generated/a_competitive_look_at_the_media_industry/IMG_7310-750x500-29a72e.JPG 562w 2x, /images/generated/a_competitive_look_at_the_media_industry/IMG_7310-1500x1000-29a72e.JPG 2x, /images/generated/a_competitive_look_at_the_media_industry/IMG_7310-750x500-29a72e.JPG&quot; alt=&quot;Competitive Analysis Whiteboard Chart&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;p&gt;There are several dimensions that we couldn’t cover in this visualization, such as audience size, the amount of content produced, and level of interactivity. In the end, that’s the joy and sorrow of research frameworks: you can’t always account for every force in the world, but you can make sense of a few key influences, at least.&lt;/p&gt;

&lt;p&gt;Without further adieu, then, let’s just present the final chart and see what you make of it:&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 79.67586508979414%;&quot;&gt;&lt;img src=&quot;/images/generated/a_competitive_look_at_the_media_industry/graph_publishing-2-750x598-3773dd.png&quot; srcset=&quot;/images/generated/a_competitive_look_at_the_media_industry/graph_publishing-2-750x598-3773dd.png 562w, /images/generated/a_competitive_look_at_the_media_industry/graph_publishing-2-750x598-3773dd.png 562w 2x, /images/generated/a_competitive_look_at_the_media_industry/graph_publishing-2-1500x1194-3773dd.png 2x, /images/generated/a_competitive_look_at_the_media_industry/graph_publishing-2-750x598-3773dd.png&quot; alt=&quot;Competitive Analysis Whiteboard Chart&quot; width=&quot;750&quot; height=&quot;597&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;key-findings-and-takeaways&quot;&gt;Key Findings and Takeaways&lt;/h3&gt;

&lt;p&gt;As shown in the diagram, media organizations such as CNN, which indeed started life as a then-novel “cable news network”, have expanded both their format and frequency coverage over the years, sometimes in a “downward” fashion, chasing the high-frequency text content area of the space. This expansion gives the organization and the brand the ability to operate in a “continuous” nature across different media types. Expansion also gives publishers a measure of resilience against adverse market changes, such as the slowly looming and long-foretold death of print media, as NYT and Time have realized.&lt;/p&gt;

&lt;h3 id=&quot;implications-for-design-and-moving-forward&quot;&gt;Implications for Design and Moving Forward&lt;/h3&gt;

&lt;p&gt;Anyway, where are the gaps in this space? The “low-fidelity”, high-frequency corner of the chart is pretty crowded, but there might be some headroom up in the “Future” box—an area representing interactive, immersive multimedia content, published on a less frequent schedule. Content like this would probably take more time and money to produce, but there are organizations with the resources and editorial interest in such a space, such as National Geographic.&lt;/p&gt;

&lt;p&gt;We need to explore and interview more to investigate the potential in this space, but the use of our own wild ideas for a visualization framework proved to be very useful indeed. &lt;/p&gt;

&lt;p&gt;Furthermore, we can use this activity, which in essence was a distant observation activity of what’s currently being produced out there, to further narrow down our project scope. We now know that our target publication modality should be those with frequencies closer to weekly and monthly editions and content types that are more expository or exploratory in nature.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/a_competitive_look_at_the_media_industry&quot;&gt;A Competitive Look at the Media Industry&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on May 29, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Intel Portland Trip]]></title>
  <link>/blog/intel_portland_trip;_put_a_bird_on_it</link>
  <id>/blog/intel_portland_trip;_put_a_bird_on_it</id>
  <published>2014-05-24T00:00:00-07:00</published>
  <updated>2014-05-24T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;Our team scheduled a meeting with Mike Premi at the Intel’s Jones Farm campus at Hillsboro, OR for May 24th. We packed a Mini Cooper with four of us and drove all the way from Seattle to Hillsboro. Our fifth member joined online using conference software once the meeting was rolling. We were warmly welcomed and started off by getting to know each other a bit better. Next we dove into the discussions around project ideas. As we signed an NDA with Intel, we won’t be able to disclose major portions of the meeting. Overall, the meeting was successful and we were invited for a dinner at a nearby sushi restaurant. The day didn’t end here; overwhelmed with ideas shown and discussions we had with Mike, we couldn’t stop ourselves from having an ideation session in our hotel room.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 133.33333333333331%;&quot;&gt;&lt;img src=&quot;/images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_20140524_174550-750x1000-3cb992.jpg&quot; srcset=&quot;/images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_20140524_174550-750x1000-3cb992.jpg 562w, /images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_20140524_174550-750x1000-3cb992.jpg 562w 2x, /images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_20140524_174550-1500x2000-3cb992.jpg 2x, /images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_20140524_174550-750x1000-3cb992.jpg&quot; alt=&quot;Joe and food&quot; width=&quot;750&quot; height=&quot;1000&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_7134-750x500-90aca5.JPG&quot; srcset=&quot;/images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_7134-750x500-90aca5.JPG 562w, /images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_7134-750x500-90aca5.JPG 562w 2x, /images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_7134-1500x1000-90aca5.JPG 2x, /images/generated/intel_portland_trip;_put_a_bird_on_it/IMG_7134-750x500-90aca5.JPG&quot; alt=&quot;Hotel room ideation&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;key-observations-and-takeaway&quot;&gt;Key Observations and Takeaway&lt;/h3&gt;

&lt;p&gt;The meeting with Mike helped us better understand the constraints that we will be working under. Primarily, the underlying goal is to make the Intel’s tablets and 2-in-1’s using Perceptual Technology more valuable, with a further focus on changing the publishing industry. The meeting also helped us gained a ton of insights and possible directions from design solutions we were shown. We were questioning the rationale behind some of these solutions, which led us to identify gaps and possible interventions in the problem space. We were asking ourselves questions like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We need to create 3D content first to be able consume later. How can journalists create compelling 3D content?&lt;/li&gt;
  &lt;li&gt;How can we create a coffee table-like experience in the digital world? The emotion is missing.&lt;/li&gt;
  &lt;li&gt;Explorative vs. Imaginative. Books vs. Movies. Explore vs. Explain.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;implications-for-design-and-moving-forward&quot;&gt;Implications for Design and Moving Forward&lt;/h3&gt;

&lt;p&gt;The meeting had a huge impact on the direction that we were earlier intending to take our project towards. The recognized constraints will help us channel the project. We also convinced ourselves that the publish space is full of interesting and compelling opportunities.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/intel_portland_trip;_put_a_bird_on_it&quot;&gt;Intel Portland Trip&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on May 24, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Wii Sports Resort Usability Evaluation]]></title>
  <link>/blog/wii_sports_resort_usability_evaluation</link>
  <id>/blog/wii_sports_resort_usability_evaluation</id>
  <published>2014-05-22T00:00:00-07:00</published>
  <updated>2014-05-22T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;One of our research hypotheses was that interacting with an active 3D gesture interface, where interactions are communicated with the main device through a remote or supplementary device, such as the Wii remote would be easier and more enjoyable than interacting with hand gestures alone (Passive 3D gesture systems like Kinect). Therefore, We conducted a usability test on the Wii, testing both generic Wii menu interactions, and the gameplay interactions on a game called Wii Sports Resort. We first asked participants about their general gameplay habits and if they were familiar with the Wii. Participants were asked to open the game from the Wii home menu, and navigate to both the Swordplay and Table Tennis games. They were then asked to play a couple rounds of each game. After two rounds of a game had been completed, we interviewed the participants about their experience playing the game: what they thought about the controls, level of difficulty, and their level of enjoyment. After both games had been completed, we asked them to rate their overall experience of gameplay, and to give specific examples.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.69135802469135%;&quot;&gt;&lt;img src=&quot;/images/generated/wii_sports_resort_usability_evaluation/5-750x560-a49201.JPG&quot; srcset=&quot;/images/generated/wii_sports_resort_usability_evaluation/5-750x560-a49201.JPG 562w, /images/generated/wii_sports_resort_usability_evaluation/5-750x560-a49201.JPG 562w 2x, /images/generated/wii_sports_resort_usability_evaluation/5-1500x1120-a49201.JPG 2x, /images/generated/wii_sports_resort_usability_evaluation/5-750x560-a49201.JPG&quot; alt=&quot;Participant 1 Chaoyu using wii sports resort&quot; width=&quot;750&quot; height=&quot;560&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/wii_sports_resort_usability_evaluation/IMG_20140522_180012-750x563-43d266.jpg&quot; srcset=&quot;/images/generated/wii_sports_resort_usability_evaluation/IMG_20140522_180012-750x563-43d266.jpg 562w, /images/generated/wii_sports_resort_usability_evaluation/IMG_20140522_180012-750x563-43d266.jpg 562w 2x, /images/generated/wii_sports_resort_usability_evaluation/IMG_20140522_180012-1500x1124-43d266.jpg 2x, /images/generated/wii_sports_resort_usability_evaluation/IMG_20140522_180012-750x563-43d266.jpg&quot; alt=&quot;Participant 2 Anna using wii sports resort&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;key-observations-and-takeaway&quot;&gt;Key Observations and Takeaway&lt;/h3&gt;

&lt;p&gt;Based on what we saw during gameplay, we came up with a tentative theory as to why some users may prefer remote-assisted gestures to pure hand gestures: The remote, in this case the Wii remote, was something tangible to the user, and so the user felt more in control of their actions when using the remote versus using only their hands. In completing this exercise, we rediscovered the value of conducting a usability test with novice users. In addition to this being a good practice in general when attracting and keeping new customers, we also found that features we took for granted were not necessarily obvious or easy to use for novice users. We also discovered one of the challenges of conducting a usability test on a game: Think-aloud protocol, i.e. getting the tester to talk about what they are doing or feeling while using an interface, is not necessarily a good idea in the context of testing a game. We found that when our participants had to think about what they were doing and articulate it to us in the moment, their gameplay suffered. This in turn created a feedback loop of talking about challenges and frustrations, which caused their performance to suffer. Consequently, our task completion time findings were not as accurate as they could’ve been.&lt;/p&gt;

&lt;h3 id=&quot;implications-for-design-and-moving-forward&quot;&gt;Implications for Design and Moving Forward&lt;/h3&gt;

&lt;p&gt;Based on our observations and participant responses, we think the tangibility and haptic feedback of a physical controller provides a more concrete mapping, helping the user to feel more in-control of the situation.
Our findings have indicated the importance of visual feedback and mapping when designing an interface. Speed, interval between action/result, and force are something else to consider when designing gestures. The Wii interface is something we will keep in mind once we start prototyping.&lt;/p&gt;

&lt;p&gt;Once we thought about our findings, we realized something else interesting: Do users generally prefer active 3D gestures because they are much more responsive and accurate than their passive counterparts? Would their preference change if the passive ones were just as good as the active ones? What if they were better? In order to address these questions, we have planned to do a second round of usability testing, this time incorporating a Wizard-Of-Oz method: What would happen if we Wizard-Of-Oz the passive 3D interactions systems so that they are performing as well as the active ones? We have planned this research activity for the week of June 23rd. &lt;/p&gt;

&lt;p&gt;&lt;em&gt;Media Needed:
Usability Testing Image (research —&amp;gt; evaluative research —&amp;gt; photos from heuristic analysis and usability testing)&lt;/em&gt;&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/blog/wii_sports_resort_usability_evaluation&quot;&gt;Wii Sports Resort Usability Evaluation&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on May 22, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Heuristic Evaluation of the Nintendo Wii]]></title>
  <link>/blog/heuristic_evaluation_of_the_nintendo_wii</link>
  <id>/blog/heuristic_evaluation_of_the_nintendo_wii</id>
  <published>2014-05-22T00:00:00-07:00</published>
  <updated>2014-05-22T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;In order to better understand a generally well-regarded area of the current gesture technology product space, we chose to do a heuristic evaluation, or expert usability test, of the Wii system and a specific game, Wii Sports Resort. In keeping with best practices,we chose to follow Nielsen’s Ten Standards of Usability Heuristics, but also added metrics that we felt were specifically relevant to gameplay. We created a paper form that we could use to keep track of interface problems, heuristic violations, and other notes about the experience of the interface. We also rated the problems with regards to the severity of the violation. When evaluating the interface, we went through every aspect of the generic Wii menu that we could find, the Wii Sports Resort menu, and a few more Wii apps and Sports Resort games in addition to the games we were evaluating in the usability test.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/heuristic_evaluation_of_the_nintendo_wii/IMG_20140522_164842-750x563-833e48.jpg&quot; srcset=&quot;/images/generated/heuristic_evaluation_of_the_nintendo_wii/IMG_20140522_164842-750x563-833e48.jpg 562w, /images/generated/heuristic_evaluation_of_the_nintendo_wii/IMG_20140522_164842-750x563-833e48.jpg 562w 2x, /images/generated/heuristic_evaluation_of_the_nintendo_wii/IMG_20140522_164842-1500x1124-833e48.jpg 2x, /images/generated/heuristic_evaluation_of_the_nintendo_wii/IMG_20140522_164842-750x563-833e48.jpg&quot; alt=&quot;The team working on heuristic evaluation&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.69135802469135%;&quot;&gt;&lt;img src=&quot;/images/generated/heuristic_evaluation_of_the_nintendo_wii/4-750x560-1bc3f9.JPG&quot; srcset=&quot;/images/generated/heuristic_evaluation_of_the_nintendo_wii/4-750x560-1bc3f9.JPG 562w, /images/generated/heuristic_evaluation_of_the_nintendo_wii/4-750x560-1bc3f9.JPG 562w 2x, /images/generated/heuristic_evaluation_of_the_nintendo_wii/4-1500x1120-1bc3f9.JPG 2x, /images/generated/heuristic_evaluation_of_the_nintendo_wii/4-750x560-1bc3f9.JPG&quot; alt=&quot;Wii instructions during practice sessions&quot; width=&quot;750&quot; height=&quot;560&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.69135802469135%;&quot;&gt;&lt;img src=&quot;/images/generated/heuristic_evaluation_of_the_nintendo_wii/7-750x560-b72648.JPG&quot; srcset=&quot;/images/generated/heuristic_evaluation_of_the_nintendo_wii/7-750x560-b72648.JPG 562w, /images/generated/heuristic_evaluation_of_the_nintendo_wii/7-750x560-b72648.JPG 562w 2x, /images/generated/heuristic_evaluation_of_the_nintendo_wii/7-1500x1120-b72648.JPG 2x, /images/generated/heuristic_evaluation_of_the_nintendo_wii/7-750x560-b72648.JPG&quot; alt=&quot;Wii instructions during practice sessions&quot; width=&quot;750&quot; height=&quot;560&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;key-observations-and-takeaway&quot;&gt;Key Observations and Takeaway&lt;/h3&gt;

&lt;p&gt;Though we found the inclusion of specific gameplay metrics to be useful, these metrics also made it harder to evaluate the interface based on problems alone, because we were looking for specific gameplay violations rather than categorizing the problems we found under certain heuristics. However, we did learn firsthand the value of conducting both heuristic evaluations and usability tests with end users, because it enabled us to spot the differences in the user experience for people like ourselves who are very familiar with that interface type, versus novice users. More specifically, there were cases where features that we thought were well-designed and obvious were in fact not obvious to people outside of our research group. Hence, underlining the need for combining heuristic analysis with a usability study.&lt;/p&gt;

&lt;h3 id=&quot;implications-for-design-and-moving-forward&quot;&gt;Implications for Design and Moving Forward&lt;/h3&gt;

&lt;p&gt;Though many of our metrics were specific to the gaming world, we realized that some of these metrics could still be applied to any gesture-based interface. These metrics included the ability to pause a current action, the ability to go backwards through menu levels easily, and the ability to exit a program whenever the user wishes.
The results of this evaluation have caused us to think about what heuristics would be most valuable in the evaluation of a 3D setting, and which actions would be essential to a gesture-based interaction model. Completing this evaluation has also given us a foundation for how we might go about finding the most essential visuals and tasks that a user might need for a gesture-based interface, and how to evaluate them.&lt;/p&gt;

&lt;h1 id=&quot;heuristic-evaluation-of-flipboard&quot;&gt;Heuristic Evaluation of Flipboard&lt;/h1&gt;

&lt;p&gt;Exercise Summary
We chose to do a heuristic evaluation of the app Flipboard, because it is a relatively popular news consumption platform. We started the evaluation on a Windows tablet, and then switched to an Android tablet and an Android smartphone to find out if there were platform differences. &lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 56.41025641025641%;&quot;&gt;&lt;img src=&quot;/images/generated/heuristic_evaluation_of_the_nintendo_wii/heuristic%20evaluation%20flipboard-750x423-0aab40.jpg&quot; srcset=&quot;/images/generated/heuristic_evaluation_of_the_nintendo_wii/heuristic%20evaluation%20flipboard-750x423-0aab40.jpg 562w, /images/generated/heuristic_evaluation_of_the_nintendo_wii/heuristic%20evaluation%20flipboard-750x423-0aab40.jpg 562w 2x, /images/generated/heuristic_evaluation_of_the_nintendo_wii/heuristic%20evaluation%20flipboard-1500x846-0aab40.jpg 2x, /images/generated/heuristic_evaluation_of_the_nintendo_wii/heuristic%20evaluation%20flipboard-750x423-0aab40.jpg&quot; alt=&quot;Screenshots from the heuristic evaluation of Flipboard&quot; width=&quot;750&quot; height=&quot;423&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;reflections-on-this-technique&quot;&gt;Reflections on this Technique&lt;/h3&gt;

&lt;p&gt;As this was our second heuristic evaluation, we were able to take what we had learned from the Wii heuristic evaluation and apply it to this exercise. Specifically, this involved finding problems first and categorizing them later, rather than looking for specific metrics. What was challenging with this technique was deciding which heuristics a problem violated. This was occasionally resolved by deciding that a problem violated more than one heuristic. However, an unexpected benefit of this exercise was discovering the value of testing an interface on more than one platform when possible. Through testing the app on both a Windows and Android platform, we were able to discover interface inconsistencies that may not have been found if we had only looked at one platform.&lt;/p&gt;

&lt;h3 id=&quot;reflections-on-our-design-process&quot;&gt;Reflections on our Design Process&lt;/h3&gt;

&lt;p&gt;The main insight we discovered was that the aggregation app suffered from a common problem with aggregation: pulling from multiple sites increases the likelihood of inconsistent and confusing formats between articles. Therefore, we now want to research other aggregation sites to see how others are tackling the inconsistency problem, so that our designs don’t run into the same problem. In general, we learned that it is a good idea to evaluate not only popular interfaces, but also unique and innovative interfaces for design inspiration.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Media Needed:
Photos from Research Summary deliverable
6-06 Flipboard Heuristic Analysis screenshot (Research)&lt;/em&gt;&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;/blog/heuristic_evaluation_of_the_nintendo_wii&quot;&gt;Heuristic Evaluation of the Nintendo Wii&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on May 22, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Minority Report, Are we there yet?]]></title>
  <link>/blog/minority_report,_are_we_there_yet</link>
  <id>/blog/minority_report,_are_we_there_yet</id>
  <published>2014-05-15T00:00:00-07:00</published>
  <updated>2014-05-15T00:00:00-07:00</updated>
  <author>
    <name></name>
    <uri></uri>
    <email></email>
  </author>
  <content type="html">&lt;h3 id=&quot;activity-and-process&quot;&gt;Activity and Process&lt;/h3&gt;

&lt;p&gt;After secondary research on gesture input technologies, we decided to examine several gesture based systems firsthand in order to test our personal assumptions about how gesture interfaces are implemented today. We decided to do an ethnographic study of Kinect to test the accuracy of gestures, the intuitiveness of the interaction model and how it compared with the interaction models like Wii, which use a remote instead of just hand gestures. We were also curious to know how first time users do with the use of gestures. Our thought behind this activity was that these observations would help us understand gesture-based interaction styles and learn about what works and what needs improvement to incorporate in future prototypes that we will develop for the project.&lt;/p&gt;

&lt;p&gt;We visited the Microsoft Store in University Village to interact with the Xbox One’s system menus with Kinect gestures in an environment where, just like us, the average customer would receive their first introduction to the interface. Four of us from the team who were new to the Kinect interface tried it out as first time users, and the others observed. We also observed two store employees attempt to use the Kinect.&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 75.0%;&quot;&gt;&lt;img src=&quot;/images/generated/minority_report,_are_we_there_yet/IMG_20140515_185510-750x563-91643a.jpg&quot; srcset=&quot;/images/generated/minority_report,_are_we_there_yet/IMG_20140515_185510-750x563-91643a.jpg 562w, /images/generated/minority_report,_are_we_there_yet/IMG_20140515_185510-750x563-91643a.jpg 562w 2x, /images/generated/minority_report,_are_we_there_yet/IMG_20140515_185510-1500x1124-91643a.jpg 2x, /images/generated/minority_report,_are_we_there_yet/IMG_20140515_185510-750x563-91643a.jpg&quot; alt=&quot;Joe trying the xbox settings menu&quot; width=&quot;750&quot; height=&quot;562&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;key-observations-and-takeaway&quot;&gt;Key Observations and Takeaway&lt;/h3&gt;

&lt;p&gt;With everyone that tried the system during this study, one prominent issue we came across was the lack of acknowledgement and feedback. There was no visual feedback in the form of a cursor to show actual hand gesture pointing position. The only visual feedback shown was a very thin box around the selection. This was causing confusion to the users who did not know when their gestures were working. In fact when there was more than one person in the vicinity, there was confusion about whose movements were actually initiating what the system was responding with. In one instance during our observation, we noticed that the user could not get out of a certain screen and used a workaround they claim to use often with the Kinect system; i.e. switching it off and back on. The previous example and other similar observations like unintentional selections, error prevention and correction were principles that were clearly important to us and the others using the system. There is also a lack of clarity on screen space mapping . A positive that we noticed was how the system differentiated and provided visual cues by showing voice commands in green (not related to gestures, but a good example of discoverability).&lt;/p&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 74.69135802469135%;&quot;&gt;&lt;img src=&quot;/images/generated/minority_report,_are_we_there_yet/photo%205-750x560-04c4f5.JPG&quot; srcset=&quot;/images/generated/minority_report,_are_we_there_yet/photo%205-750x560-04c4f5.JPG 562w, /images/generated/minority_report,_are_we_there_yet/photo%205-750x560-04c4f5.JPG 562w 2x, /images/generated/minority_report,_are_we_there_yet/photo%205-1500x1120-04c4f5.JPG 2x, /images/generated/minority_report,_are_we_there_yet/photo%205-750x560-04c4f5.JPG&quot; alt=&quot;Microsoft employee trying kinect&quot; width=&quot;750&quot; height=&quot;560&quot; /&gt;&lt;/figure&gt;

&lt;figure class=&quot;img-container default&quot; style=&quot;padding-bottom: 66.66666666666666%;&quot;&gt;&lt;img src=&quot;/images/generated/minority_report,_are_we_there_yet/IMG_7043-750x500-aad4ed.JPG&quot; srcset=&quot;/images/generated/minority_report,_are_we_there_yet/IMG_7043-750x500-aad4ed.JPG 562w, /images/generated/minority_report,_are_we_there_yet/IMG_7043-750x500-aad4ed.JPG 562w 2x, /images/generated/minority_report,_are_we_there_yet/IMG_7043-1500x1000-aad4ed.JPG 2x, /images/generated/minority_report,_are_we_there_yet/IMG_7043-750x500-aad4ed.JPG&quot; alt=&quot;Microsoft employee trying kinect&quot; width=&quot;750&quot; height=&quot;500&quot; /&gt;&lt;/figure&gt;

&lt;h3 id=&quot;implications-for-design-and-moving-forward&quot;&gt;Implications for Design and Moving Forward&lt;/h3&gt;

&lt;p&gt;These observations gave us a lot to think about in terms of designing systems that use gesture input. For one, feedback is critical. Responsiveness and immediate feedback to right or wrong actions is essential. Findings from this ethnographic observation have given us a good understanding of what works and what does not in gesture input systems. These will become our guiding principles for the interaction design of any concept that we decide to go with as the project progresses.&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;/blog/minority_report,_are_we_there_yet&quot;&gt;Minority Report, Are we there yet?&lt;/a&gt; was originally published by  at &lt;a href=&quot;&quot;&gt;Dynabots&lt;/a&gt; on May 15, 2014.&lt;/p&gt;</content>
</entry>

</feed>
